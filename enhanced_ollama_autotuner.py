#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import sys
import os
import logging
import time
from datetime import datetime
from typing import List, Dict, Any
import argparse

sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from src.utils.ollama_utils import get_model_size_in_billions, get_local_ollama_models
from core.enhanced_tuner import EnhancedOllamaTuner
from utils.memory_monitor import get_memory_monitor
from utils.cache_manager import get_cache_manager

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('ollama_tuner.log', encoding='utf-8')
    ]
)
logging.getLogger("httpx").setLevel(logging.WARNING)

logger = logging.getLogger(__name__)

def select_constraints_by_size(model_data: Dict) -> Dict:
    model_name = model_data.get('name') or model_data.get('model')
    size_b = get_model_size_in_billions(model_data.get('details', {}))
    
    logger.info(f"åµæ¸¬åˆ°æ¨¡å‹ '{model_name}' çš„å¤§å°ç´„ç‚º {size_b:.2f}B")
    
    if 0 < size_b < 10:
        return {
            "time_limit_s": 30.0,
            "ttft_limit_s": 2.0,
            "hallucination_threshold": 0.95,
            "num_predict": 1024
        }
    elif 10 <= size_b <= 18:
        return {
            "time_limit_s": 120.0,
            "ttft_limit_s": 6.0,
            "hallucination_threshold": 1.0,
            "num_predict": 2048
        }
    elif size_b > 18:
        return {
            "time_limit_s": 180.0,
            "ttft_limit_s": 15.0,
            "hallucination_threshold": 0.95,
            "num_predict": 8192
        }
    else:
        logger.warning("ä½¿ç”¨é€šç”¨é è¨­ç´„æŸæ¢ä»¶")
        return {
            "time_limit_s": 60.0,
            "ttft_limit_s": 5.0,
            "hallucination_threshold": 0.95,
            "num_predict": 256
        }

def generate_enhanced_html_report(results_data: List[Dict]):
    from jinja2 import Environment, FileSystemLoader
    
    report_filename = 'enhanced_ollama_tuner_report.html'
    
    try:
        if os.path.exists(report_filename):
            os.remove(report_filename)
            logger.info(f"å·²åˆªé™¤èˆŠçš„å ±å‘Šæª”æ¡ˆï¼š{report_filename}")
        
        env = Environment(loader=FileSystemLoader('.'))
        template = env.get_template('enhanced_report_template.html')
        
        report_data = {
            'results': results_data,
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'memory_summary': get_memory_monitor().get_memory_summary(),
            'cache_stats': get_cache_manager().get_cache_stats()
        }
        
        html_content = template.render(report_data)
        
        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        logger.info(f"å¢å¼·çš„ HTML å ±å‘Šå·²ç”Ÿæˆï¼š{report_filename}")
        
        try:
            import webbrowser
            webbrowser.open('file://' + os.path.abspath(report_filename))
            logger.info("æ­£åœ¨ç€è¦½å™¨ä¸­æ‰“é–‹å ±å‘Š...")
        except Exception as e:
            logger.error(f"ç„¡æ³•è‡ªå‹•æ‰“é–‹ç€è¦½å™¨ï¼š{e}")
    
    except Exception as e:
        logger.error(f"ç”Ÿæˆ HTML å ±å‘Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

def print_optimization_summary(result: Dict):
    print(f"\n{'='*60}")
    print(f"æ¨¡å‹: {result['model_name']}")
    print(f"{'='*60}")
    
    print("\nğŸ¯ æœ€ä½³è¨­å®š:")
    optimal = result['optimal_settings']
    for key, value in optimal.items():
        if key != 'detailed_evaluation':
            print(f"  {key}: {value}")
    
    print("\nâš¡ æ€§èƒ½æŒ‡æ¨™:")
    perf = result['final_performance']
    print(f"  TTFT: {perf['ttft']*1000:.0f}ms")
    print(f"  TPS: {perf['tps']:.2f} tokens/s")
    print(f"  ç¸½æ™‚é–“: {perf['duration']:.2f}s")
    
    if 'parameter_importance' in result:
        print("\nğŸ“Š åƒæ•¸é‡è¦æ€§:")
        importance = result['parameter_importance']
        for param, imp in sorted(importance.items(), key=lambda x: x[1], reverse=True):
            print(f"  {param}: {imp:.3f}")
    
    if 'optimization_history' in result:
        history = result['optimization_history']
        print(f"\nğŸ”„ å„ªåŒ–æ­·å² (å…± {len(history)} æ¬¡è¿­ä»£):")
        best_iteration = max(history, key=lambda x: x['score'])
        print(f"  æœ€ä½³è¿­ä»£: {best_iteration['iteration']} (è©•åˆ†: {best_iteration['score']:.4f})")
    
    if 'memory_summary' in result:
        print("\nğŸ’¾ è¨˜æ†¶é«”ä½¿ç”¨:")
        memory = result['memory_summary']
        if 'system_memory' in memory:
            sys_mem = memory['system_memory']
            print(f"  ç³»çµ±è¨˜æ†¶é«”: {sys_mem['current_percent']:.1f}% (å¹³å‡: {sys_mem['average_percent']:.1f}%)")
        
        if 'gpu_memory' in memory:
            for gpu_id, gpu_mem in memory['gpu_memory'].items():
                print(f"  GPU {gpu_id}: {gpu_mem['current_percent']:.1f}% (å¹³å‡: {gpu_mem['average_percent']:.1f}%)")
    
    print(f"{'='*60}\n")

def main():
    parser = argparse.ArgumentParser(
        description="å¢å¼·çš„ Ollama Auto-Tuner",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument("--model", type=str, help="æŒ‡å®šè¦é€²è¡Œèª¿æ ¡çš„ç‰¹å®šæ¨¡å‹åç¨±ã€‚")
    parser.add_argument("--time-limit", type=float, help="è‡ªå®šç¾©æ¸¬è©¦çš„æ™‚é–“é™åˆ¶ï¼ˆç§’ï¼‰ã€‚")
    parser.add_argument("--ttft-limit", type=float, help="è‡ªå®šç¾© TTFT çš„é™åˆ¶ï¼ˆç§’ï¼‰ã€‚")
    parser.add_argument("--verbose", action="store_true", help="å•Ÿç”¨è©³ç´°æ—¥èªŒè¼¸å‡º (DEBUG level)ã€‚")
    args = parser.parse_args()

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
        logger.info("å·²å•Ÿç”¨è©³ç´°æ—¥èªŒè¼¸å‡º (DEBUG level)ã€‚")

    print("ğŸš€ å¢å¼·çš„ Ollama Auto-Tuner")
    print("=" * 50)
    print("æ–°åŠŸèƒ½:")
    print("âœ… GPU/CPU è¨˜æ†¶é«”ç›£æ§")
    print("âœ… æ™ºèƒ½ç·©å­˜æ©Ÿåˆ¶")
    print("âœ… è²è‘‰æ–¯å„ªåŒ–ç®—æ³•")
    print("âœ… å¢å¼·è©•ä¼°æŒ‡æ¨™")
    print("âœ… æ—©æœŸåœæ­¢æ©Ÿåˆ¶")
    print("âœ… è‡ªé©æ‡‰åƒæ•¸ç¯„åœ")
    print("=" * 50)
    
    # æª¢æŸ¥ Ollama æœå‹™
    logger.info("æ­£åœ¨æª¢æŸ¥ Ollama æœå‹™...")
    all_local_models = get_local_ollama_models()
    
    if not all_local_models:
        logger.error("æœªæ‰¾åˆ°ä»»ä½•æœ¬åœ° Ollama æ¨¡å‹ï¼Œæˆ–ç„¡æ³•é€£æ¥åˆ° Ollama æœå‹™")
        return
    
    models_to_run = all_local_models
    if args.model:
        models_to_run = [m for m in all_local_models if m.get('model') == args.model]
        if not models_to_run:
            logger.error(f"æ‰¾ä¸åˆ°æŒ‡å®šçš„æ¨¡å‹: {args.model}")
            available_models = [m.get('model') for m in all_local_models if m.get('model')]
            logger.info(f"å¯ç”¨çš„æ¨¡å‹æœ‰: {available_models}")
            return

    model_names = [m.get('model') for m in models_to_run if m.get('model')]
    logger.info(f"å°‡ç‚º {len(models_to_run)} å€‹æ¨¡å‹é€²è¡Œèª¿æ ¡: {model_names}")
    
    memory_monitor = get_memory_monitor()
    cache_manager = get_cache_manager()
    
    memory_monitor.start_monitoring(interval=1.0)
    
    all_results = []
    start_time = time.time()
    
    try:
        for i, model_data in enumerate(models_to_run, 1):
            model_name = model_data.get('model')
            if not model_name:
                logger.warning(f"è·³éæ²’æœ‰åç¨±çš„æ¨¡å‹: {model_data}")
                continue
            
            print(f"\n{'='*20} æ¨¡å‹ {i}/{len(models_to_run)}: {model_name} {'='*20}")
            
            constraints = select_constraints_by_size(model_data)
            if args.time_limit:
                constraints['time_limit_s'] = args.time_limit
                logger.info(f"ä½¿ç”¨è‡ªå®šç¾©æ™‚é–“é™åˆ¶: {args.time_limit}s")
            if args.ttft_limit:
                constraints['ttft_limit_s'] = args.ttft_limit
                logger.info(f"ä½¿ç”¨è‡ªå®šç¾© TTFT é™åˆ¶: {args.ttft_limit}s")

            logger.info(f"ä½¿ç”¨ç´„æŸæ¢ä»¶: {constraints}")           
            tuner = EnhancedOllamaTuner(model_name=model_name, constraints=constraints)            
            result = tuner.run()
            
            if result and result != "incompatible":
                all_results.append(result)
                print_optimization_summary(result)
                        
            elif result == "incompatible":
                logger.warning(f"æ¨¡å‹ '{model_name}' ä¸æ”¯æ´ç”ŸæˆåŠŸèƒ½ï¼Œå·²è·³é")
            else:
                logger.error(f"æ¨¡å‹ '{model_name}' èª¿æ ¡å¤±æ•—")
            
            print(f"{'='*20} {model_name} èª¿æ ¡å®Œæˆ {'='*20}")
        
        if all_results:
            total_time = time.time() - start_time
            logger.info(f"æ‰€æœ‰æ¨¡å‹èª¿æ ¡å®Œæˆï¼Œç¸½è€—æ™‚: {total_time/60:.1f} åˆ†é˜")
            
            generate_enhanced_html_report(all_results)

            cache_stats = cache_manager.get_cache_stats()
            logger.info(f"ç·©å­˜çµ±è¨ˆ: {cache_stats['total_files']} å€‹æª”æ¡ˆ, {cache_stats['total_size_mb']:.2f} MB")
            
        else:
            if args.model:
                 logger.warning(f"æ¨¡å‹ '{args.model}' æœªèƒ½æˆåŠŸå®Œæˆèª¿æ ¡ã€‚")
            else:
                 logger.warning("æ²’æœ‰ä»»ä½•ç›¸å®¹çš„æ¨¡å‹æˆåŠŸå®Œæˆèª¿æ ¡ã€‚")
    
    except KeyboardInterrupt:
        logger.info("æ¥æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œæ­£åœ¨æ¸…ç†...")
    except Exception as e:
        logger.error(f"åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=args.verbose)
    finally:
        memory_monitor.stop_monitoring()
        logger.info("ç¨‹å¼åŸ·è¡Œå®Œæˆ")

if __name__ == "__main__":
    main()
