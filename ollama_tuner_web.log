2025-09-04 23:35:21,041 - src.utils.memory_monitor - INFO - è¨˜æ†¶é«”ç›£æ§å·²å•Ÿå‹•
2025-09-04 23:35:21,042 - __main__ - INFO - ğŸŒ Web UI å·²å•Ÿå‹•: http://0.0.0.0:5000
2025-09-04 23:35:21,050 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.64:5000
2025-09-04 23:35:21,050 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-04 23:35:22,043 - src.utils.ollama_utils - INFO - Attempting to fetch local models from Ollama service...
2025-09-04 23:35:22,097 - src.utils.ollama_utils - INFO - Received response from ollama.list(): models=[Model(model='qwen3:30b-a3b', modified_at=datetime.datetime(2025, 8, 31, 12, 17, 35, 223433, tzinfo=TzInfo(+08:00)), digest='e50831eb2d919df6268f18bc3cec980d597ae27e98c3308f90a0ec4941b64f28', size=18556699301, details=ModelDetails(parent_model='', format='gguf', family='qwen3moe', families=['qwen3moe'], parameter_size='30.5B', quantization_level='Q4_K_M')), Model(model='gpt-oss:20b', modified_at=datetime.datetime(2025, 8, 24, 8, 42, 55, 8404, tzinfo=TzInfo(+08:00)), digest='aa4295ac10c3afb60e6d711289fc6896f5aef82258997b9efdaed6d0cc4cd8b8', size=13780173724, details=ModelDetails(parent_model='', format='gguf', family='gptoss', families=['gptoss'], parameter_size='20.9B', quantization_level='MXFP4')), Model(model='gemma3:4b', modified_at=datetime.datetime(2025, 8, 20, 23, 55, 2, 564934, tzinfo=TzInfo(+08:00)), digest='a2af6cc3eb7fa8be8504abaf9b04e88f17a119ec3f04a3addf55f92841195f5a', size=3338801804, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='4.3B', quantization_level='Q4_K_M'))]
2025-09-04 23:35:22,097 - src.ui.web_interface - INFO - Broadcasting available_models event with data: {'models': ['qwen3:30b-a3b', 'gpt-oss:20b', 'gemma3:4b']}
2025-09-04 23:35:25,875 - werkzeug - INFO - 127.0.0.1 - - [04/Sep/2025 23:35:25] "GET / HTTP/1.1" 200 -
2025-09-04 23:35:26,427 - werkzeug - INFO - 127.0.0.1 - - [04/Sep/2025 23:35:26] "GET /socket.io/?EIO=4&transport=polling&t=PaLNa_L HTTP/1.1" 200 -
2025-09-04 23:35:26,463 - src.ui.web_interface - INFO - Web UI å®¢æˆ¶ç«¯å·²é€£æ¥
2025-09-04 23:35:26,463 - werkzeug - INFO - 127.0.0.1 - - [04/Sep/2025 23:35:26] "POST /socket.io/?EIO=4&transport=polling&t=PaLNa_w&sid=kwOLXk8URyt8RaBnAAAA HTTP/1.1" 200 -
2025-09-04 23:35:26,465 - werkzeug - INFO - 127.0.0.1 - - [04/Sep/2025 23:35:26] "GET /socket.io/?EIO=4&transport=polling&t=PaLNa_x&sid=kwOLXk8URyt8RaBnAAAA HTTP/1.1" 200 -
2025-09-04 23:35:26,469 - werkzeug - INFO - 127.0.0.1 - - [04/Sep/2025 23:35:26] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-09-04 23:35:26,475 - werkzeug - INFO - 127.0.0.1 - - [04/Sep/2025 23:35:26] "GET /socket.io/?EIO=4&transport=polling&t=PaLNb08&sid=kwOLXk8URyt8RaBnAAAA HTTP/1.1" 200 -
2025-09-04 23:35:35,496 - src.utils.ollama_utils - INFO - Attempting to fetch local models from Ollama service...
2025-09-04 23:35:35,507 - src.utils.ollama_utils - INFO - Received response from ollama.list(): models=[Model(model='qwen3:30b-a3b', modified_at=datetime.datetime(2025, 8, 31, 12, 17, 35, 223433, tzinfo=TzInfo(+08:00)), digest='e50831eb2d919df6268f18bc3cec980d597ae27e98c3308f90a0ec4941b64f28', size=18556699301, details=ModelDetails(parent_model='', format='gguf', family='qwen3moe', families=['qwen3moe'], parameter_size='30.5B', quantization_level='Q4_K_M')), Model(model='gpt-oss:20b', modified_at=datetime.datetime(2025, 8, 24, 8, 42, 55, 8404, tzinfo=TzInfo(+08:00)), digest='aa4295ac10c3afb60e6d711289fc6896f5aef82258997b9efdaed6d0cc4cd8b8', size=13780173724, details=ModelDetails(parent_model='', format='gguf', family='gptoss', families=['gptoss'], parameter_size='20.9B', quantization_level='MXFP4')), Model(model='gemma3:4b', modified_at=datetime.datetime(2025, 8, 20, 23, 55, 2, 564934, tzinfo=TzInfo(+08:00)), digest='a2af6cc3eb7fa8be8504abaf9b04e88f17a119ec3f04a3addf55f92841195f5a', size=3338801804, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='4.3B', quantization_level='Q4_K_M'))]
2025-09-04 23:35:35,507 - src.core.enhanced_tuner - INFO - å¢å¼·èª¿æ ¡å™¨å·²åˆå§‹åŒ–: gemma3:4b
2025-09-04 23:35:35,507 - src.core.enhanced_tuner - INFO - é–‹å§‹ç‚ºæ¨¡å‹ 'gemma3:4b' é€²è¡Œå¢å¼·èª¿æ ¡
2025-09-04 23:35:35,507 - src.core.enhanced_tuner - INFO - é–‹å§‹è²è‘‰æ–¯å„ªåŒ–å“è³ªèª¿æ ¡
2025-09-04 23:35:35,508 - src.core.enhanced_tuner - INFO - è¿­ä»£ 1/25: æ¸¬è©¦åƒæ•¸ {'temperature': 1.4781112191504056, 'top_p': 0.6120614616046784, 'top_k': 103.60671670500341}
2025-09-04 23:35:43,845 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-04 23:35:43,845 - src.models.bayesian_optimizer - INFO - ç™¼ç¾æ–°çš„æœ€ä½³çµæœ: 0.4411 with params: {'temperature': 1.4781112191504056, 'top_p': 0.6120614616046784, 'top_k': 103.60671670500341}
2025-09-04 23:35:43,845 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.4411
2025-09-04 23:35:43,845 - src.core.enhanced_tuner - INFO - è¿­ä»£ 2/25: æ¸¬è©¦åƒæ•¸ {'temperature': 0.7565761595640909, 'top_p': 0.7597388687319261, 'top_k': 69.34651150748871}
2025-09-04 23:35:48,266 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-04 23:35:48,271 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.4369
2025-09-04 23:35:48,271 - src.core.enhanced_tuner - INFO - è¿­ä»£ 3/25: æ¸¬è©¦åƒæ•¸ {'temperature': 1.3357726049921073, 'top_p': 0.9829073730995694, 'top_k': 110.82939898005058}
2025-09-04 23:35:52,924 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-04 23:35:52,924 - src.models.bayesian_optimizer - INFO - ç™¼ç¾æ–°çš„æœ€ä½³çµæœ: 0.4950 with params: {'temperature': 1.3357726049921073, 'top_p': 0.9829073730995694, 'top_k': 110.82939898005058}
2025-09-04 23:35:52,937 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.4950
2025-09-04 23:35:52,938 - src.core.enhanced_tuner - INFO - è¿­ä»£ 4/25: æ¸¬è©¦åƒæ•¸ {'temperature': 1.436118499269723, 'top_p': 0.8156220607430367, 'top_k': 12.653617970091938}
2025-09-04 23:35:57,336 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-04 23:35:57,347 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.4944
2025-09-04 23:35:57,347 - src.core.enhanced_tuner - INFO - è¿­ä»£ 5/25: æ¸¬è©¦åƒæ•¸ {'temperature': 0.24589677892743034, 'top_p': 0.8525818260219942, 'top_k': 6.332070078498679}
2025-09-04 23:36:01,696 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-04 23:36:01,706 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.4411
2025-09-04 23:36:01,708 - src.core.enhanced_tuner - INFO - è¿­ä»£ 6/25: æ¸¬è©¦åƒæ•¸ {'temperature': 1.3582014302647651, 'top_p': 0.5031409417508472, 'top_k': 84.57921869582849}
2025-09-04 23:36:05,766 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-04 23:36:05,766 - src.models.bayesian_optimizer - INFO - ç™¼ç¾æ–°çš„æœ€ä½³çµæœ: 0.4986 with params: {'temperature': 1.3582014302647651, 'top_p': 0.5031409417508472, 'top_k': 84.57921869582849}
2025-09-04 23:36:05,771 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.4986
2025-09-04 23:36:05,771 - src.core.enhanced_tuner - INFO - è¿­ä»£ 7/25: æ¸¬è©¦åƒæ•¸ {'temperature': 1.0981085272724584, 'top_p': 0.9029311062742911, 'top_k': 134.30601712104786}
2025-09-04 23:36:09,928 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-04 23:36:09,934 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.4444
2025-09-04 23:36:09,934 - src.core.enhanced_tuner - INFO - è¿­ä»£ 8/25: æ¸¬è©¦åƒæ•¸ {'temperature': 1.0916356504193958, 'top_p': 0.7847680165739477, 'top_k': 68.74570074665868}
2025-09-04 23:36:14,103 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-04 23:36:14,103 - src.models.bayesian_optimizer - INFO - ç™¼ç¾æ–°çš„æœ€ä½³çµæœ: 0.5039 with params: {'temperature': 1.0916356504193958, 'top_p': 0.7847680165739477, 'top_k': 68.74570074665868}
2025-09-04 23:36:14,108 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.5039
2025-09-04 23:36:14,108 - src.core.enhanced_tuner - INFO - è§¸ç™¼æ—©åœæ¢ä»¶
2025-09-04 23:36:17,941 - src.core.enhanced_tuner - INFO - æœ€ä½³å“è³ªè¨­å®š: {'temperature': 1.0916356504193958, 'top_p': 0.7847680165739477, 'top_k': 68.74570074665868} (è©•åˆ†: 0.5039)
2025-09-04 23:36:17,941 - src.core.enhanced_tuner - INFO - é–‹å§‹ä¸Šä¸‹æ–‡çª—å£èª¿æ ¡
2025-09-04 23:36:17,941 - src.core.enhanced_tuner - INFO - æ¸¬è©¦ num_ctx = 8192
2025-09-04 23:36:21,039 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-04 23:36:21,039 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=3.10s, TTFT=422ms, TPS=104.34
2025-09-04 23:36:21,039 - src.core.enhanced_tuner - INFO - æ‰¾åˆ°å¯æ¥å—çš„ num_ctx: 8192
2025-09-04 23:36:21,039 - src.core.enhanced_tuner - INFO - é–‹å§‹ GPU å±¤æ•¸èª¿æ ¡
2025-09-04 23:36:21,040 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 50
2025-09-04 23:36:26,143 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-04 23:36:26,143 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=5.10s, TTFT=2286ms, TPS=100.10
2025-09-04 23:36:26,143 - src.core.enhanced_tuner - INFO - å¤±æ•—ï¼Œå˜—è©¦æ›´ä½å€¼
2025-09-04 23:36:26,143 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 24
2025-09-04 23:36:39,485 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-04 23:36:39,485 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=13.34s, TTFT=4493ms, TPS=35.04
2025-09-04 23:36:39,485 - src.core.enhanced_tuner - INFO - å¤±æ•—ï¼Œå˜—è©¦æ›´ä½å€¼
2025-09-04 23:36:39,485 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 11
2025-09-04 23:37:03,903 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-04 23:37:03,903 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=24.42s, TTFT=12316ms, TPS=24.71
2025-09-04 23:37:03,903 - src.core.enhanced_tuner - INFO - å¤±æ•—ï¼Œå˜—è©¦æ›´ä½å€¼
2025-09-04 23:37:03,903 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 5
2025-09-04 23:37:30,032 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-04 23:37:30,032 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=26.13s, TTFT=13969ms, TPS=22.70
2025-09-04 23:37:30,032 - src.core.enhanced_tuner - INFO - å¤±æ•—ï¼Œå˜—è©¦æ›´ä½å€¼
2025-09-04 23:37:30,033 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 2
2025-09-04 23:37:58,105 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-04 23:37:58,105 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=28.07s, TTFT=14481ms, TPS=21.27
2025-09-04 23:37:58,105 - src.core.enhanced_tuner - INFO - å¤±æ•—ï¼Œå˜—è©¦æ›´ä½å€¼
2025-09-04 23:37:58,105 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 1
2025-09-04 23:38:26,061 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-04 23:38:26,061 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=27.95s, TTFT=14793ms, TPS=21.05
2025-09-04 23:38:26,061 - src.core.enhanced_tuner - INFO - å¤±æ•—ï¼Œå˜—è©¦æ›´ä½å€¼
2025-09-04 23:38:55,152 - src.core.enhanced_tuner - WARNING - æœ€çµ‚ç¢ºèªå¤±æ•—ï¼Œä½¿ç”¨ CPU
2025-09-04 23:39:17,803 - src.core.enhanced_tuner - INFO - å¢å¼·èª¿æ ¡å®Œæˆ
2025-09-04 23:39:18,316 - src.utils.memory_monitor - INFO - è¨˜æ†¶é«”ç›£æ§å·²åœæ­¢
2025-09-04 23:39:50,677 - werkzeug - INFO - 127.0.0.1 - - [04/Sep/2025 23:39:50] "GET /enhanced_ollama_tuner_report.html HTTP/1.1" 200 -
2025-09-04 23:40:20,487 - __main__ - INFO - æ¥æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œæ­£åœ¨é—œé–‰...
2025-09-04 23:40:20,488 - src.utils.memory_monitor - INFO - è¨˜æ†¶é«”ç›£æ§å·²åœæ­¢
2025-09-04 23:40:20,488 - __main__ - INFO - ç¨‹å¼åŸ·è¡Œå®Œæˆ
2025-09-05 00:07:59,074 - src.utils.memory_monitor - INFO - è¨˜æ†¶é«”ç›£æ§å·²å•Ÿå‹•
2025-09-05 00:07:59,075 - __main__ - INFO - ğŸŒ Web UI å·²å•Ÿå‹•: http://0.0.0.0:5000
2025-09-05 00:07:59,081 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.64:5000
2025-09-05 00:07:59,081 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-05 00:08:00,076 - src.utils.ollama_utils - INFO - Attempting to fetch local models from Ollama service...
2025-09-05 00:08:00,080 - src.utils.ollama_utils - INFO - Received response from ollama.list(): models=[Model(model='qwen3:30b-a3b', modified_at=datetime.datetime(2025, 8, 31, 12, 17, 35, 223433, tzinfo=TzInfo(+08:00)), digest='e50831eb2d919df6268f18bc3cec980d597ae27e98c3308f90a0ec4941b64f28', size=18556699301, details=ModelDetails(parent_model='', format='gguf', family='qwen3moe', families=['qwen3moe'], parameter_size='30.5B', quantization_level='Q4_K_M')), Model(model='gpt-oss:20b', modified_at=datetime.datetime(2025, 8, 24, 8, 42, 55, 8404, tzinfo=TzInfo(+08:00)), digest='aa4295ac10c3afb60e6d711289fc6896f5aef82258997b9efdaed6d0cc4cd8b8', size=13780173724, details=ModelDetails(parent_model='', format='gguf', family='gptoss', families=['gptoss'], parameter_size='20.9B', quantization_level='MXFP4')), Model(model='gemma3:4b', modified_at=datetime.datetime(2025, 8, 20, 23, 55, 2, 564934, tzinfo=TzInfo(+08:00)), digest='a2af6cc3eb7fa8be8504abaf9b04e88f17a119ec3f04a3addf55f92841195f5a', size=3338801804, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='4.3B', quantization_level='Q4_K_M'))]
2025-09-05 00:08:00,080 - src.ui.web_interface - INFO - Broadcasting available_models event with data: {'models': ['qwen3:30b-a3b', 'gpt-oss:20b', 'gemma3:4b']}
2025-09-05 00:08:04,409 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:08:04] "GET / HTTP/1.1" 200 -
2025-09-05 00:08:05,195 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:08:05] "GET /socket.io/?EIO=4&transport=polling&t=PaLV3D7 HTTP/1.1" 200 -
2025-09-05 00:08:05,234 - src.ui.web_interface - INFO - Web UI å®¢æˆ¶ç«¯å·²é€£æ¥
2025-09-05 00:08:05,234 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:08:05] "POST /socket.io/?EIO=4&transport=polling&t=PaLV3DV&sid=8dzfmEQbsbTo-GM2AAAA HTTP/1.1" 200 -
2025-09-05 00:08:05,235 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:08:05] "GET /socket.io/?EIO=4&transport=polling&t=PaLV3DV.0&sid=8dzfmEQbsbTo-GM2AAAA HTTP/1.1" 200 -
2025-09-05 00:08:05,251 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:08:05] "GET /socket.io/?EIO=4&transport=polling&t=PaLV3D_&sid=8dzfmEQbsbTo-GM2AAAA HTTP/1.1" 200 -
2025-09-05 00:08:05,287 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:08:05] "GET /socket.io/?EIO=4&transport=polling&t=PaLV3EY&sid=8dzfmEQbsbTo-GM2AAAA HTTP/1.1" 200 -
2025-09-05 00:08:14,801 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:08:14] "GET /?lang=zh HTTP/1.1" 200 -
2025-09-05 00:08:14,833 - src.ui.web_interface - INFO - Web UI å®¢æˆ¶ç«¯å·²æ–·é–‹
2025-09-05 00:08:14,834 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:08:14] "GET /socket.io/?EIO=4&transport=websocket&sid=8dzfmEQbsbTo-GM2AAAA HTTP/1.1" 200 -
2025-09-05 00:08:14,970 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:08:14] "GET /socket.io/?EIO=4&transport=polling&t=PaLV5bs HTTP/1.1" 200 -
2025-09-05 00:08:14,990 - src.ui.web_interface - INFO - Web UI å®¢æˆ¶ç«¯å·²é€£æ¥
2025-09-05 00:08:14,991 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:08:14] "POST /socket.io/?EIO=4&transport=polling&t=PaLV5cA&sid=cKaRWYJ-Sw5d-y8kAAAC HTTP/1.1" 200 -
2025-09-05 00:08:14,991 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:08:14] "GET /socket.io/?EIO=4&transport=polling&t=PaLV5cA.0&sid=cKaRWYJ-Sw5d-y8kAAAC HTTP/1.1" 200 -
2025-09-05 00:08:15,003 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:08:15] "GET /socket.io/?EIO=4&transport=polling&t=PaLV5cO&sid=cKaRWYJ-Sw5d-y8kAAAC HTTP/1.1" 200 -
2025-09-05 00:08:19,667 - src.utils.ollama_utils - INFO - Attempting to fetch local models from Ollama service...
2025-09-05 00:08:19,673 - src.utils.ollama_utils - INFO - Received response from ollama.list(): models=[Model(model='qwen3:30b-a3b', modified_at=datetime.datetime(2025, 8, 31, 12, 17, 35, 223433, tzinfo=TzInfo(+08:00)), digest='e50831eb2d919df6268f18bc3cec980d597ae27e98c3308f90a0ec4941b64f28', size=18556699301, details=ModelDetails(parent_model='', format='gguf', family='qwen3moe', families=['qwen3moe'], parameter_size='30.5B', quantization_level='Q4_K_M')), Model(model='gpt-oss:20b', modified_at=datetime.datetime(2025, 8, 24, 8, 42, 55, 8404, tzinfo=TzInfo(+08:00)), digest='aa4295ac10c3afb60e6d711289fc6896f5aef82258997b9efdaed6d0cc4cd8b8', size=13780173724, details=ModelDetails(parent_model='', format='gguf', family='gptoss', families=['gptoss'], parameter_size='20.9B', quantization_level='MXFP4')), Model(model='gemma3:4b', modified_at=datetime.datetime(2025, 8, 20, 23, 55, 2, 564934, tzinfo=TzInfo(+08:00)), digest='a2af6cc3eb7fa8be8504abaf9b04e88f17a119ec3f04a3addf55f92841195f5a', size=3338801804, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='4.3B', quantization_level='Q4_K_M'))]
2025-09-05 00:08:19,673 - src.core.enhanced_tuner - INFO - å¢å¼·èª¿æ ¡å™¨å·²åˆå§‹åŒ–: gemma3:4b
2025-09-05 00:08:19,673 - src.core.enhanced_tuner - INFO - é–‹å§‹ç‚ºæ¨¡å‹ 'gemma3:4b' é€²è¡Œå¢å¼·èª¿æ ¡
2025-09-05 00:08:19,674 - src.core.enhanced_tuner - INFO - é–‹å§‹è²è‘‰æ–¯å„ªåŒ–å“è³ªèª¿æ ¡
2025-09-05 00:08:19,674 - src.core.enhanced_tuner - INFO - è¿­ä»£ 1/25: æ¸¬è©¦åƒæ•¸ {'temperature': 1.3431154328483945, 'top_p': 0.8944104250852905, 'top_k': 63.48873359054824}
2025-09-05 00:08:19,674 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 1.3431154328483945, 'top_p': 0.8944104250852905, 'top_k': 63.48873359054824}
2025-09-05 00:08:26,537 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:08:28,547 - src.core.new_enhanced_evaluator - ERROR - HumanEval åŸ·è¡Œå‡ºéŒ¯: evaluate_functional_correctness() got an unexpected keyword argument 'problems'
2025-09-05 00:08:28,549 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:08:28,549 - src.models.bayesian_optimizer - INFO - ç™¼ç¾æ–°çš„æœ€ä½³çµæœ: 0.3239 with params: {'temperature': 1.3431154328483945, 'top_p': 0.8944104250852905, 'top_k': 63.48873359054824}
2025-09-05 00:08:28,549 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3239
2025-09-05 00:08:28,549 - src.core.enhanced_tuner - INFO - è¿­ä»£ 2/25: æ¸¬è©¦åƒæ•¸ {'temperature': 1.4687738064124638, 'top_p': 0.9242535123361784, 'top_k': 73.04790999571881}
2025-09-05 00:08:28,549 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 1.4687738064124638, 'top_p': 0.9242535123361784, 'top_k': 73.04790999571881}
2025-09-05 00:08:34,214 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:08:36,246 - src.core.new_enhanced_evaluator - ERROR - HumanEval åŸ·è¡Œå‡ºéŒ¯: evaluate_functional_correctness() got an unexpected keyword argument 'problems'
2025-09-05 00:08:36,247 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:08:36,247 - src.models.bayesian_optimizer - INFO - ç™¼ç¾æ–°çš„æœ€ä½³çµæœ: 0.3677 with params: {'temperature': 1.4687738064124638, 'top_p': 0.9242535123361784, 'top_k': 73.04790999571881}
2025-09-05 00:08:36,252 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3677
2025-09-05 00:08:36,253 - src.core.enhanced_tuner - INFO - è¿­ä»£ 3/25: æ¸¬è©¦åƒæ•¸ {'temperature': 0.8981770360442215, 'top_p': 0.6580503412455969, 'top_k': 140.16772422060137}
2025-09-05 00:08:36,253 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 0.8981770360442215, 'top_p': 0.6580503412455969, 'top_k': 140.16772422060137}
2025-09-05 00:08:42,059 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:08:44,082 - src.core.new_enhanced_evaluator - ERROR - HumanEval åŸ·è¡Œå‡ºéŒ¯: evaluate_functional_correctness() got an unexpected keyword argument 'problems'
2025-09-05 00:08:44,083 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:08:44,083 - src.models.bayesian_optimizer - INFO - ç™¼ç¾æ–°çš„æœ€ä½³çµæœ: 0.3717 with params: {'temperature': 0.8981770360442215, 'top_p': 0.6580503412455969, 'top_k': 140.16772422060137}
2025-09-05 00:08:44,092 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3717
2025-09-05 00:08:44,093 - src.core.enhanced_tuner - INFO - è¿­ä»£ 4/25: æ¸¬è©¦åƒæ•¸ {'temperature': 0.2029527821565433, 'top_p': 0.822597532772839, 'top_k': 134.74864137923902}
2025-09-05 00:08:44,094 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 0.2029527821565433, 'top_p': 0.822597532772839, 'top_k': 134.74864137923902}
2025-09-05 00:08:49,494 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:08:51,610 - src.core.new_enhanced_evaluator - ERROR - HumanEval åŸ·è¡Œå‡ºéŒ¯: evaluate_functional_correctness() got an unexpected keyword argument 'problems'
2025-09-05 00:08:51,611 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:08:51,618 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3321
2025-09-05 00:08:51,618 - src.core.enhanced_tuner - INFO - è¿­ä»£ 5/25: æ¸¬è©¦åƒæ•¸ {'temperature': 0.5802548590679615, 'top_p': 0.6814657550627665, 'top_k': 125.91313810571734}
2025-09-05 00:08:51,619 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 0.5802548590679615, 'top_p': 0.6814657550627665, 'top_k': 125.91313810571734}
2025-09-05 00:08:57,312 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:08:59,482 - src.core.new_enhanced_evaluator - ERROR - HumanEval åŸ·è¡Œå‡ºéŒ¯: evaluate_functional_correctness() got an unexpected keyword argument 'problems'
2025-09-05 00:08:59,483 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:08:59,493 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3308
2025-09-05 00:08:59,494 - src.core.enhanced_tuner - INFO - è¿­ä»£ 6/25: æ¸¬è©¦åƒæ•¸ {'temperature': 0.7590282510887999, 'top_p': 0.674363206619023, 'top_k': 123.31426376845154}
2025-09-05 00:08:59,494 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 0.7590282510887999, 'top_p': 0.674363206619023, 'top_k': 123.31426376845154}
2025-09-05 00:09:04,935 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:09:06,987 - src.core.new_enhanced_evaluator - ERROR - HumanEval åŸ·è¡Œå‡ºéŒ¯: evaluate_functional_correctness() got an unexpected keyword argument 'problems'
2025-09-05 00:09:06,988 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:09:06,994 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3421
2025-09-05 00:09:06,995 - src.core.enhanced_tuner - INFO - è¿­ä»£ 7/25: æ¸¬è©¦åƒæ•¸ {'temperature': 1.0807003981917287, 'top_p': 0.5038303183653307, 'top_k': 12.366435847767274}
2025-09-05 00:09:06,995 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 1.0807003981917287, 'top_p': 0.5038303183653307, 'top_k': 12.366435847767274}
2025-09-05 00:09:12,378 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:09:14,542 - src.core.new_enhanced_evaluator - ERROR - HumanEval åŸ·è¡Œå‡ºéŒ¯: evaluate_functional_correctness() got an unexpected keyword argument 'problems'
2025-09-05 00:09:14,543 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:09:14,552 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3306
2025-09-05 00:09:14,552 - src.core.enhanced_tuner - INFO - è§¸ç™¼æ—©åœæ¢ä»¶
2025-09-05 00:09:14,553 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 0.8981770360442215, 'top_p': 0.6580503412455969, 'top_k': 140.16772422060137}
2025-09-05 00:09:20,258 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:09:22,407 - src.core.new_enhanced_evaluator - ERROR - HumanEval åŸ·è¡Œå‡ºéŒ¯: evaluate_functional_correctness() got an unexpected keyword argument 'problems'
2025-09-05 00:09:22,408 - src.core.enhanced_tuner - INFO - æœ€ä½³å“è³ªè¨­å®š: {'temperature': 0.8981770360442215, 'top_p': 0.6580503412455969, 'top_k': 140.16772422060137} (è©•åˆ†: 0.3717)
2025-09-05 00:09:22,408 - src.core.enhanced_tuner - INFO - é–‹å§‹ä¸Šä¸‹æ–‡çª—å£èª¿æ ¡
2025-09-05 00:09:22,408 - src.core.enhanced_tuner - INFO - æ¸¬è©¦ num_ctx = 8192
2025-09-05 00:09:25,270 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:09:25,270 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=2.86s, TTFT=438ms, TPS=96.18
2025-09-05 00:09:25,270 - src.core.enhanced_tuner - INFO - æ‰¾åˆ°å¯æ¥å—çš„ num_ctx: 8192
2025-09-05 00:09:25,271 - src.core.enhanced_tuner - INFO - é–‹å§‹ GPU å±¤æ•¸èª¿æ ¡
2025-09-05 00:09:25,271 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 50
2025-09-05 00:09:30,490 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:09:30,490 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=5.22s, TTFT=2248ms, TPS=97.67
2025-09-05 00:09:30,491 - src.core.enhanced_tuner - INFO - å¤±æ•—ï¼Œå˜—è©¦æ›´ä½å€¼
2025-09-05 00:09:30,491 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 24
2025-09-05 00:09:44,026 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:09:44,026 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=13.53s, TTFT=4637ms, TPS=34.28
2025-09-05 00:09:44,027 - src.core.enhanced_tuner - INFO - å¤±æ•—ï¼Œå˜—è©¦æ›´ä½å€¼
2025-09-05 00:09:44,027 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 11
2025-09-05 00:10:07,684 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:10:07,684 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=23.65s, TTFT=12364ms, TPS=25.51
2025-09-05 00:10:07,684 - src.core.enhanced_tuner - INFO - å¤±æ•—ï¼Œå˜—è©¦æ›´ä½å€¼
2025-09-05 00:10:07,685 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 5
2025-09-05 00:10:35,137 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:10:35,137 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=27.45s, TTFT=13989ms, TPS=22.80
2025-09-05 00:10:35,137 - src.core.enhanced_tuner - INFO - å¤±æ•—ï¼Œå˜—è©¦æ›´ä½å€¼
2025-09-05 00:10:35,138 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 2
2025-09-05 00:11:03,864 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:11:03,864 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=28.73s, TTFT=14820ms, TPS=21.22
2025-09-05 00:11:03,864 - src.core.enhanced_tuner - INFO - å¤±æ•—ï¼Œå˜—è©¦æ›´ä½å€¼
2025-09-05 00:11:03,864 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 1
2025-09-05 00:11:29,033 - __main__ - INFO - æ”¶åˆ°åœæ­¢èª¿æ ¡ä¿¡è™Ÿ
2025-09-05 00:11:33,429 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:11:33,430 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=29.56s, TTFT=15202ms, TPS=21.10
2025-09-05 00:11:33,430 - src.core.enhanced_tuner - INFO - å¤±æ•—ï¼Œå˜—è©¦æ›´ä½å€¼
2025-09-05 00:12:01,521 - src.core.enhanced_tuner - WARNING - æœ€çµ‚ç¢ºèªå¤±æ•—ï¼Œä½¿ç”¨ CPU
2025-09-05 00:12:22,900 - src.utils.memory_monitor - INFO - è¨˜æ†¶é«”ç›£æ§å·²åœæ­¢
2025-09-05 00:12:48,995 - __main__ - INFO - æ¥æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œæ­£åœ¨é—œé–‰...
2025-09-05 00:12:48,995 - src.utils.memory_monitor - INFO - è¨˜æ†¶é«”ç›£æ§å·²åœæ­¢
2025-09-05 00:12:48,996 - __main__ - INFO - ç¨‹å¼åŸ·è¡Œå®Œæˆ
2025-09-05 00:13:10,674 - src.utils.memory_monitor - INFO - è¨˜æ†¶é«”ç›£æ§å·²å•Ÿå‹•
2025-09-05 00:13:10,676 - __main__ - INFO - ğŸŒ Web UI å·²å•Ÿå‹•: http://0.0.0.0:5000
2025-09-05 00:13:10,681 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.64:5000
2025-09-05 00:13:10,681 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-05 00:13:11,374 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:13:11] "GET /socket.io/?EIO=4&transport=polling&t=PaLWDyu HTTP/1.1" 200 -
2025-09-05 00:13:11,382 - src.ui.web_interface - INFO - Web UI å®¢æˆ¶ç«¯å·²é€£æ¥
2025-09-05 00:13:11,383 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:13:11] "POST /socket.io/?EIO=4&transport=polling&t=PaLWDzH&sid=vXF0jG-o_6gDS6QSAAAA HTTP/1.1" 200 -
2025-09-05 00:13:11,384 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:13:11] "GET /socket.io/?EIO=4&transport=polling&t=PaLWDzI&sid=vXF0jG-o_6gDS6QSAAAA HTTP/1.1" 200 -
2025-09-05 00:13:11,388 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:13:11] "GET /socket.io/?EIO=4&transport=polling&t=PaLWDzQ&sid=vXF0jG-o_6gDS6QSAAAA HTTP/1.1" 200 -
2025-09-05 00:13:11,678 - src.utils.ollama_utils - INFO - Attempting to fetch local models from Ollama service...
2025-09-05 00:13:11,682 - src.utils.ollama_utils - INFO - Received response from ollama.list(): models=[Model(model='qwen3:30b-a3b', modified_at=datetime.datetime(2025, 8, 31, 12, 17, 35, 223433, tzinfo=TzInfo(+08:00)), digest='e50831eb2d919df6268f18bc3cec980d597ae27e98c3308f90a0ec4941b64f28', size=18556699301, details=ModelDetails(parent_model='', format='gguf', family='qwen3moe', families=['qwen3moe'], parameter_size='30.5B', quantization_level='Q4_K_M')), Model(model='gpt-oss:20b', modified_at=datetime.datetime(2025, 8, 24, 8, 42, 55, 8404, tzinfo=TzInfo(+08:00)), digest='aa4295ac10c3afb60e6d711289fc6896f5aef82258997b9efdaed6d0cc4cd8b8', size=13780173724, details=ModelDetails(parent_model='', format='gguf', family='gptoss', families=['gptoss'], parameter_size='20.9B', quantization_level='MXFP4')), Model(model='gemma3:4b', modified_at=datetime.datetime(2025, 8, 20, 23, 55, 2, 564934, tzinfo=TzInfo(+08:00)), digest='a2af6cc3eb7fa8be8504abaf9b04e88f17a119ec3f04a3addf55f92841195f5a', size=3338801804, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='4.3B', quantization_level='Q4_K_M'))]
2025-09-05 00:13:11,682 - src.ui.web_interface - INFO - Broadcasting available_models event with data: {'models': ['qwen3:30b-a3b', 'gpt-oss:20b', 'gemma3:4b']}
2025-09-05 00:13:12,739 - src.ui.web_interface - INFO - Web UI å®¢æˆ¶ç«¯å·²æ–·é–‹
2025-09-05 00:13:12,739 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:13:12] "GET /socket.io/?EIO=4&transport=websocket&sid=vXF0jG-o_6gDS6QSAAAA HTTP/1.1" 200 -
2025-09-05 00:13:19,592 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:13:19] "GET / HTTP/1.1" 200 -
2025-09-05 00:13:19,857 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:13:19] "GET /socket.io/?EIO=4&transport=polling&t=PaLWG1i HTTP/1.1" 200 -
2025-09-05 00:13:19,881 - src.ui.web_interface - INFO - Web UI å®¢æˆ¶ç«¯å·²é€£æ¥
2025-09-05 00:13:19,881 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:13:19] "POST /socket.io/?EIO=4&transport=polling&t=PaLWG24&sid=2uQk8ghEnlPV7pa2AAAC HTTP/1.1" 200 -
2025-09-05 00:13:19,881 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:13:19] "GET /socket.io/?EIO=4&transport=polling&t=PaLWG25&sid=2uQk8ghEnlPV7pa2AAAC HTTP/1.1" 200 -
2025-09-05 00:13:19,912 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:13:19] "GET /socket.io/?EIO=4&transport=polling&t=PaLWG2Y&sid=2uQk8ghEnlPV7pa2AAAC HTTP/1.1" 200 -
2025-09-05 00:13:32,529 - src.utils.ollama_utils - INFO - Attempting to fetch local models from Ollama service...
2025-09-05 00:13:32,534 - src.utils.ollama_utils - INFO - Received response from ollama.list(): models=[Model(model='qwen3:30b-a3b', modified_at=datetime.datetime(2025, 8, 31, 12, 17, 35, 223433, tzinfo=TzInfo(+08:00)), digest='e50831eb2d919df6268f18bc3cec980d597ae27e98c3308f90a0ec4941b64f28', size=18556699301, details=ModelDetails(parent_model='', format='gguf', family='qwen3moe', families=['qwen3moe'], parameter_size='30.5B', quantization_level='Q4_K_M')), Model(model='gpt-oss:20b', modified_at=datetime.datetime(2025, 8, 24, 8, 42, 55, 8404, tzinfo=TzInfo(+08:00)), digest='aa4295ac10c3afb60e6d711289fc6896f5aef82258997b9efdaed6d0cc4cd8b8', size=13780173724, details=ModelDetails(parent_model='', format='gguf', family='gptoss', families=['gptoss'], parameter_size='20.9B', quantization_level='MXFP4')), Model(model='gemma3:4b', modified_at=datetime.datetime(2025, 8, 20, 23, 55, 2, 564934, tzinfo=TzInfo(+08:00)), digest='a2af6cc3eb7fa8be8504abaf9b04e88f17a119ec3f04a3addf55f92841195f5a', size=3338801804, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='4.3B', quantization_level='Q4_K_M'))]
2025-09-05 00:13:32,535 - src.core.enhanced_tuner - INFO - å¢å¼·èª¿æ ¡å™¨å·²åˆå§‹åŒ–: gemma3:4b
2025-09-05 00:13:32,535 - src.core.enhanced_tuner - INFO - é–‹å§‹ç‚ºæ¨¡å‹ 'gemma3:4b' é€²è¡Œå¢å¼·èª¿æ ¡
2025-09-05 00:13:32,536 - src.core.enhanced_tuner - INFO - é–‹å§‹è²è‘‰æ–¯å„ªåŒ–å“è³ªèª¿æ ¡
2025-09-05 00:13:32,536 - src.core.enhanced_tuner - INFO - è¿­ä»£ 1/25: æ¸¬è©¦åƒæ•¸ {'temperature': 1.209290091134415, 'top_p': 0.955414552828862, 'top_k': 35.438717338710184}
2025-09-05 00:13:32,537 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 1.209290091134415, 'top_p': 0.955414552828862, 'top_k': 35.438717338710184}
2025-09-05 00:13:55,610 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:14:05,177 - src.core.new_enhanced_evaluator - ERROR - HumanEval åŸ·è¡Œå‡ºéŒ¯: 'human_eval_example_0'
Traceback (most recent call last):
  File "C:\Users\HOME\Desktop\LLM-Bench-main\src\core\new_enhanced_evaluator.py", line 114, in evaluate_coding
    pass_at_k_results = evaluate_functional_correctness(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HOME\AppData\Local\Programs\Python\Python311\Lib\site-packages\human_eval\evaluation.py", line 66, in evaluate_functional_correctness
    args = (problems[task_id], completion, timeout, completion_id[task_id])
            ~~~~~~~~^^^^^^^^^
KeyError: 'human_eval_example_0'
2025-09-05 00:14:05,178 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:14:05,178 - src.models.bayesian_optimizer - INFO - ç™¼ç¾æ–°çš„æœ€ä½³çµæœ: 0.3800 with params: {'temperature': 1.209290091134415, 'top_p': 0.955414552828862, 'top_k': 35.438717338710184}
2025-09-05 00:14:05,179 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3800
2025-09-05 00:14:05,179 - src.core.enhanced_tuner - INFO - è¿­ä»£ 2/25: æ¸¬è©¦åƒæ•¸ {'temperature': 0.6248899431717359, 'top_p': 0.5242141000352212, 'top_k': 23.17995627100204}
2025-09-05 00:14:05,179 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 0.6248899431717359, 'top_p': 0.5242141000352212, 'top_k': 23.17995627100204}
2025-09-05 00:14:07,750 - src.ui.web_interface - INFO - Web UI å®¢æˆ¶ç«¯å·²æ–·é–‹
2025-09-05 00:14:07,751 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:14:07] "GET /socket.io/?EIO=4&transport=websocket&sid=2uQk8ghEnlPV7pa2AAAC HTTP/1.1" 200 -
2025-09-05 00:14:09,600 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:14:09] "GET /socket.io/?EIO=4&transport=polling&t=PaLWSAz HTTP/1.1" 200 -
2025-09-05 00:14:09,604 - src.ui.web_interface - INFO - Web UI å®¢æˆ¶ç«¯å·²é€£æ¥
2025-09-05 00:14:09,605 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:14:09] "POST /socket.io/?EIO=4&transport=polling&t=PaLWSB3&sid=LCI2kQFlwAazfnUwAAAE HTTP/1.1" 200 -
2025-09-05 00:14:09,606 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:14:09] "GET /socket.io/?EIO=4&transport=polling&t=PaLWSB3.0&sid=LCI2kQFlwAazfnUwAAAE HTTP/1.1" 200 -
2025-09-05 00:14:28,216 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:14:37,646 - src.core.new_enhanced_evaluator - ERROR - HumanEval åŸ·è¡Œå‡ºéŒ¯: 'human_eval_example_0'
Traceback (most recent call last):
  File "C:\Users\HOME\Desktop\LLM-Bench-main\src\core\new_enhanced_evaluator.py", line 114, in evaluate_coding
    pass_at_k_results = evaluate_functional_correctness(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HOME\AppData\Local\Programs\Python\Python311\Lib\site-packages\human_eval\evaluation.py", line 66, in evaluate_functional_correctness
    args = (problems[task_id], completion, timeout, completion_id[task_id])
            ~~~~~~~~^^^^^^^^^
KeyError: 'human_eval_example_0'
2025-09-05 00:14:37,647 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:14:37,652 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3402
2025-09-05 00:14:37,652 - src.core.enhanced_tuner - INFO - è¿­ä»£ 3/25: æ¸¬è©¦åƒæ•¸ {'temperature': 1.1408184727570447, 'top_p': 0.8881699801267969, 'top_k': 54.84699459076636}
2025-09-05 00:14:37,653 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 1.1408184727570447, 'top_p': 0.8881699801267969, 'top_k': 54.84699459076636}
2025-09-05 00:14:57,627 - __main__ - INFO - æ¥æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œæ­£åœ¨é—œé–‰...
2025-09-05 00:14:59,100 - src.utils.memory_monitor - INFO - è¨˜æ†¶é«”ç›£æ§å·²åœæ­¢
2025-09-05 00:14:59,100 - __main__ - INFO - ç¨‹å¼åŸ·è¡Œå®Œæˆ
2025-09-05 00:18:39,212 - src.utils.memory_monitor - INFO - è¨˜æ†¶é«”ç›£æ§å·²å•Ÿå‹•
2025-09-05 00:18:39,213 - __main__ - INFO - ğŸŒ Web UI å·²å•Ÿå‹•: http://0.0.0.0:5000
2025-09-05 00:18:39,220 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.64:5000
2025-09-05 00:18:39,220 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-05 00:18:40,214 - src.utils.ollama_utils - INFO - Attempting to fetch local models from Ollama service...
2025-09-05 00:18:40,220 - src.utils.ollama_utils - INFO - Received response from ollama.list(): models=[Model(model='qwen3:30b-a3b', modified_at=datetime.datetime(2025, 8, 31, 12, 17, 35, 223433, tzinfo=TzInfo(+08:00)), digest='e50831eb2d919df6268f18bc3cec980d597ae27e98c3308f90a0ec4941b64f28', size=18556699301, details=ModelDetails(parent_model='', format='gguf', family='qwen3moe', families=['qwen3moe'], parameter_size='30.5B', quantization_level='Q4_K_M')), Model(model='gpt-oss:20b', modified_at=datetime.datetime(2025, 8, 24, 8, 42, 55, 8404, tzinfo=TzInfo(+08:00)), digest='aa4295ac10c3afb60e6d711289fc6896f5aef82258997b9efdaed6d0cc4cd8b8', size=13780173724, details=ModelDetails(parent_model='', format='gguf', family='gptoss', families=['gptoss'], parameter_size='20.9B', quantization_level='MXFP4')), Model(model='gemma3:4b', modified_at=datetime.datetime(2025, 8, 20, 23, 55, 2, 564934, tzinfo=TzInfo(+08:00)), digest='a2af6cc3eb7fa8be8504abaf9b04e88f17a119ec3f04a3addf55f92841195f5a', size=3338801804, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='4.3B', quantization_level='Q4_K_M'))]
2025-09-05 00:18:40,220 - src.ui.web_interface - INFO - Broadcasting available_models event with data: {'models': ['qwen3:30b-a3b', 'gpt-oss:20b', 'gemma3:4b']}
2025-09-05 00:18:42,613 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:18:42] "GET /socket.io/?EIO=4&transport=polling&t=PaLXUqj HTTP/1.1" 200 -
2025-09-05 00:18:42,622 - src.ui.web_interface - INFO - Web UI å®¢æˆ¶ç«¯å·²é€£æ¥
2025-09-05 00:18:42,623 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:18:42] "POST /socket.io/?EIO=4&transport=polling&t=PaLXUqx&sid=Pnx09G7G_9OqoZF6AAAA HTTP/1.1" 200 -
2025-09-05 00:18:42,624 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:18:42] "GET /socket.io/?EIO=4&transport=polling&t=PaLXUqz&sid=Pnx09G7G_9OqoZF6AAAA HTTP/1.1" 200 -
2025-09-05 00:18:47,585 - src.ui.web_interface - INFO - Web UI å®¢æˆ¶ç«¯å·²æ–·é–‹
2025-09-05 00:18:47,585 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:18:47] "GET /socket.io/?EIO=4&transport=websocket&sid=Pnx09G7G_9OqoZF6AAAA HTTP/1.1" 200 -
2025-09-05 00:18:49,831 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:18:49] "GET / HTTP/1.1" 200 -
2025-09-05 00:18:50,388 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:18:50] "GET /socket.io/?EIO=4&transport=polling&t=PaLXWkH HTTP/1.1" 200 -
2025-09-05 00:18:50,415 - src.ui.web_interface - INFO - Web UI å®¢æˆ¶ç«¯å·²é€£æ¥
2025-09-05 00:18:50,415 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:18:50] "POST /socket.io/?EIO=4&transport=polling&t=PaLXWke&sid=N4jV1UGVY2C2rg2IAAAC HTTP/1.1" 200 -
2025-09-05 00:18:50,416 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:18:50] "GET /socket.io/?EIO=4&transport=polling&t=PaLXWkf&sid=N4jV1UGVY2C2rg2IAAAC HTTP/1.1" 200 -
2025-09-05 00:18:50,427 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:18:50] "GET /socket.io/?EIO=4&transport=polling&t=PaLXWkt&sid=N4jV1UGVY2C2rg2IAAAC HTTP/1.1" 200 -
2025-09-05 00:18:54,061 - src.utils.ollama_utils - INFO - Attempting to fetch local models from Ollama service...
2025-09-05 00:18:54,066 - src.utils.ollama_utils - INFO - Received response from ollama.list(): models=[Model(model='qwen3:30b-a3b', modified_at=datetime.datetime(2025, 8, 31, 12, 17, 35, 223433, tzinfo=TzInfo(+08:00)), digest='e50831eb2d919df6268f18bc3cec980d597ae27e98c3308f90a0ec4941b64f28', size=18556699301, details=ModelDetails(parent_model='', format='gguf', family='qwen3moe', families=['qwen3moe'], parameter_size='30.5B', quantization_level='Q4_K_M')), Model(model='gpt-oss:20b', modified_at=datetime.datetime(2025, 8, 24, 8, 42, 55, 8404, tzinfo=TzInfo(+08:00)), digest='aa4295ac10c3afb60e6d711289fc6896f5aef82258997b9efdaed6d0cc4cd8b8', size=13780173724, details=ModelDetails(parent_model='', format='gguf', family='gptoss', families=['gptoss'], parameter_size='20.9B', quantization_level='MXFP4')), Model(model='gemma3:4b', modified_at=datetime.datetime(2025, 8, 20, 23, 55, 2, 564934, tzinfo=TzInfo(+08:00)), digest='a2af6cc3eb7fa8be8504abaf9b04e88f17a119ec3f04a3addf55f92841195f5a', size=3338801804, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='4.3B', quantization_level='Q4_K_M'))]
2025-09-05 00:18:54,067 - src.core.enhanced_tuner - INFO - å¢å¼·èª¿æ ¡å™¨å·²åˆå§‹åŒ–: gemma3:4b
2025-09-05 00:18:54,067 - src.core.enhanced_tuner - INFO - é–‹å§‹ç‚ºæ¨¡å‹ 'gemma3:4b' é€²è¡Œå¢å¼·èª¿æ ¡
2025-09-05 00:18:54,067 - src.core.enhanced_tuner - INFO - é–‹å§‹è²è‘‰æ–¯å„ªåŒ–å“è³ªèª¿æ ¡
2025-09-05 00:18:54,067 - src.core.enhanced_tuner - INFO - è¿­ä»£ 1/25: æ¸¬è©¦åƒæ•¸ {'temperature': 1.380156494443236, 'top_p': 0.866736629000495, 'top_k': 106.98209072533207}
2025-09-05 00:18:54,068 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 1.380156494443236, 'top_p': 0.866736629000495, 'top_k': 106.98209072533207}
2025-09-05 00:18:54,070 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:19:17,364 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:19:39,695 - src.core.new_enhanced_evaluator - ERROR - HumanEval åŸ·è¡Œå‡ºéŒ¯: Some problems are not attempted.
Traceback (most recent call last):
  File "C:\Users\HOME\Desktop\LLM-Bench-main\src\core\new_enhanced_evaluator.py", line 114, in evaluate_coding
    pass_at_k_results = evaluate_functional_correctness(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HOME\AppData\Local\Programs\Python\Python311\Lib\site-packages\human_eval\evaluation.py", line 73, in evaluate_functional_correctness
    assert len(completion_id) == len(problems), "Some problems are not attempted."
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: Some problems are not attempted.
2025-09-05 00:19:39,696 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:19:39,696 - src.models.bayesian_optimizer - INFO - ç™¼ç¾æ–°çš„æœ€ä½³çµæœ: 0.3671 with params: {'temperature': 1.380156494443236, 'top_p': 0.866736629000495, 'top_k': 106.98209072533207}
2025-09-05 00:19:39,696 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3671
2025-09-05 00:19:39,696 - src.core.enhanced_tuner - INFO - è¿­ä»£ 2/25: æ¸¬è©¦åƒæ•¸ {'temperature': 1.1802057033084041, 'top_p': 0.6172172231476762, 'top_k': 39.824274567799094}
2025-09-05 00:19:39,698 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 1.1802057033084041, 'top_p': 0.6172172231476762, 'top_k': 39.824274567799094}
2025-09-05 00:19:39,699 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:20:05,653 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:20:08,395 - __main__ - INFO - æ¥æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œæ­£åœ¨é—œé–‰...
2025-09-05 00:20:09,144 - src.utils.memory_monitor - INFO - è¨˜æ†¶é«”ç›£æ§å·²åœæ­¢
2025-09-05 00:20:09,145 - __main__ - INFO - ç¨‹å¼åŸ·è¡Œå®Œæˆ
2025-09-05 00:23:30,070 - src.utils.memory_monitor - INFO - è¨˜æ†¶é«”ç›£æ§å·²å•Ÿå‹•
2025-09-05 00:23:30,071 - __main__ - INFO - ğŸŒ Web UI å·²å•Ÿå‹•: http://0.0.0.0:5000
2025-09-05 00:23:30,078 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.64:5000
2025-09-05 00:23:30,078 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-05 00:23:30,139 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:23:30] "GET /socket.io/?EIO=4&transport=polling&t=PaLYafQ HTTP/1.1" 200 -
2025-09-05 00:23:30,147 - src.ui.web_interface - INFO - Web UI å®¢æˆ¶ç«¯å·²é€£æ¥
2025-09-05 00:23:30,148 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:23:30] "POST /socket.io/?EIO=4&transport=polling&t=PaLYb1V&sid=Isxq3pQENZAIS7X7AAAA HTTP/1.1" 200 -
2025-09-05 00:23:30,169 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:23:30] "GET /socket.io/?EIO=4&transport=polling&t=PaLYb1q&sid=Isxq3pQENZAIS7X7AAAA HTTP/1.1" 200 -
2025-09-05 00:23:31,073 - src.utils.ollama_utils - INFO - Attempting to fetch local models from Ollama service...
2025-09-05 00:23:31,082 - src.utils.ollama_utils - INFO - Received response from ollama.list(): models=[Model(model='qwen3:30b-a3b', modified_at=datetime.datetime(2025, 8, 31, 12, 17, 35, 223433, tzinfo=TzInfo(+08:00)), digest='e50831eb2d919df6268f18bc3cec980d597ae27e98c3308f90a0ec4941b64f28', size=18556699301, details=ModelDetails(parent_model='', format='gguf', family='qwen3moe', families=['qwen3moe'], parameter_size='30.5B', quantization_level='Q4_K_M')), Model(model='gpt-oss:20b', modified_at=datetime.datetime(2025, 8, 24, 8, 42, 55, 8404, tzinfo=TzInfo(+08:00)), digest='aa4295ac10c3afb60e6d711289fc6896f5aef82258997b9efdaed6d0cc4cd8b8', size=13780173724, details=ModelDetails(parent_model='', format='gguf', family='gptoss', families=['gptoss'], parameter_size='20.9B', quantization_level='MXFP4')), Model(model='gemma3:4b', modified_at=datetime.datetime(2025, 8, 20, 23, 55, 2, 564934, tzinfo=TzInfo(+08:00)), digest='a2af6cc3eb7fa8be8504abaf9b04e88f17a119ec3f04a3addf55f92841195f5a', size=3338801804, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='4.3B', quantization_level='Q4_K_M'))]
2025-09-05 00:23:31,082 - src.ui.web_interface - INFO - Broadcasting available_models event with data: {'models': ['qwen3:30b-a3b', 'gpt-oss:20b', 'gemma3:4b']}
2025-09-05 00:23:36,199 - src.ui.web_interface - INFO - Web UI å®¢æˆ¶ç«¯å·²æ–·é–‹
2025-09-05 00:23:36,200 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:23:36] "GET /socket.io/?EIO=4&transport=websocket&sid=Isxq3pQENZAIS7X7AAAA HTTP/1.1" 200 -
2025-09-05 00:23:37,870 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:23:37] "GET / HTTP/1.1" 200 -
2025-09-05 00:23:38,517 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:23:38] "GET /socket.io/?EIO=4&transport=polling&t=PaLYd4I HTTP/1.1" 200 -
2025-09-05 00:23:38,543 - src.ui.web_interface - INFO - Web UI å®¢æˆ¶ç«¯å·²é€£æ¥
2025-09-05 00:23:38,544 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:23:38] "POST /socket.io/?EIO=4&transport=polling&t=PaLYd4f&sid=nqIJdqgv4-PcMvqmAAAC HTTP/1.1" 200 -
2025-09-05 00:23:38,546 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:23:38] "GET /socket.io/?EIO=4&transport=polling&t=PaLYd4g&sid=nqIJdqgv4-PcMvqmAAAC HTTP/1.1" 200 -
2025-09-05 00:23:38,553 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:23:38] "GET /socket.io/?EIO=4&transport=polling&t=PaLYd4s&sid=nqIJdqgv4-PcMvqmAAAC HTTP/1.1" 200 -
2025-09-05 00:23:43,344 - src.utils.ollama_utils - INFO - Attempting to fetch local models from Ollama service...
2025-09-05 00:23:43,350 - src.utils.ollama_utils - INFO - Received response from ollama.list(): models=[Model(model='qwen3:30b-a3b', modified_at=datetime.datetime(2025, 8, 31, 12, 17, 35, 223433, tzinfo=TzInfo(+08:00)), digest='e50831eb2d919df6268f18bc3cec980d597ae27e98c3308f90a0ec4941b64f28', size=18556699301, details=ModelDetails(parent_model='', format='gguf', family='qwen3moe', families=['qwen3moe'], parameter_size='30.5B', quantization_level='Q4_K_M')), Model(model='gpt-oss:20b', modified_at=datetime.datetime(2025, 8, 24, 8, 42, 55, 8404, tzinfo=TzInfo(+08:00)), digest='aa4295ac10c3afb60e6d711289fc6896f5aef82258997b9efdaed6d0cc4cd8b8', size=13780173724, details=ModelDetails(parent_model='', format='gguf', family='gptoss', families=['gptoss'], parameter_size='20.9B', quantization_level='MXFP4')), Model(model='gemma3:4b', modified_at=datetime.datetime(2025, 8, 20, 23, 55, 2, 564934, tzinfo=TzInfo(+08:00)), digest='a2af6cc3eb7fa8be8504abaf9b04e88f17a119ec3f04a3addf55f92841195f5a', size=3338801804, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='4.3B', quantization_level='Q4_K_M'))]
2025-09-05 00:23:43,350 - src.core.enhanced_tuner - INFO - å¢å¼·èª¿æ ¡å™¨å·²åˆå§‹åŒ–: gemma3:4b
2025-09-05 00:23:43,350 - src.core.enhanced_tuner - INFO - é–‹å§‹ç‚ºæ¨¡å‹ 'gemma3:4b' é€²è¡Œå¢å¼·èª¿æ ¡
2025-09-05 00:23:43,351 - src.core.enhanced_tuner - INFO - é–‹å§‹è²è‘‰æ–¯å„ªåŒ–å“è³ªèª¿æ ¡
2025-09-05 00:23:43,351 - src.core.enhanced_tuner - INFO - è¿­ä»£ 1/25: æ¸¬è©¦åƒæ•¸ {'temperature': 0.5212534776232004, 'top_p': 0.8502500993459106, 'top_k': 106.91579653806455}
2025-09-05 00:23:43,352 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 0.5212534776232004, 'top_p': 0.8502500993459106, 'top_k': 106.91579653806455}
2025-09-05 00:23:43,354 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:24:06,746 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:24:17,176 - src.core.new_enhanced_evaluator - ERROR - HumanEval åŸ·è¡Œå‡ºéŒ¯: 'task_id'
Traceback (most recent call last):
  File "C:\Users\HOME\Desktop\LLM-Bench-main\src\core\new_enhanced_evaluator.py", line 92, in evaluate_coding
    pass_at_k_results = evaluate_functional_correctness(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HOME\AppData\Local\Programs\Python\Python311\Lib\site-packages\human_eval\evaluation.py", line 52, in evaluate_functional_correctness
    problems = read_problems(problem_file)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HOME\AppData\Local\Programs\Python\Python311\Lib\site-packages\human_eval\data.py", line 12, in read_problems
    return {task["task_id"]: task for task in stream_jsonl(evalset_file)}
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HOME\AppData\Local\Programs\Python\Python311\Lib\site-packages\human_eval\data.py", line 12, in <dictcomp>
    return {task["task_id"]: task for task in stream_jsonl(evalset_file)}
            ~~~~^^^^^^^^^^^
KeyError: 'task_id'
2025-09-05 00:24:17,178 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:24:17,178 - src.models.bayesian_optimizer - INFO - ç™¼ç¾æ–°çš„æœ€ä½³çµæœ: 0.3433 with params: {'temperature': 0.5212534776232004, 'top_p': 0.8502500993459106, 'top_k': 106.91579653806455}
2025-09-05 00:24:17,178 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3433
2025-09-05 00:24:17,179 - src.core.enhanced_tuner - INFO - è¿­ä»£ 2/25: æ¸¬è©¦åƒæ•¸ {'temperature': 0.3658226098237374, 'top_p': 0.5074264470326847, 'top_k': 11.932669230465853}
2025-09-05 00:24:17,179 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 0.3658226098237374, 'top_p': 0.5074264470326847, 'top_k': 11.932669230465853}
2025-09-05 00:24:17,182 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:24:31,756 - __main__ - INFO - æ¥æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œæ­£åœ¨é—œé–‰...
2025-09-05 00:24:33,548 - src.utils.memory_monitor - INFO - è¨˜æ†¶é«”ç›£æ§å·²åœæ­¢
2025-09-05 00:24:33,549 - __main__ - INFO - ç¨‹å¼åŸ·è¡Œå®Œæˆ
2025-09-05 00:27:50,947 - src.utils.memory_monitor - INFO - è¨˜æ†¶é«”ç›£æ§å·²å•Ÿå‹•
2025-09-05 00:27:50,948 - __main__ - INFO - ğŸŒ Web UI å·²å•Ÿå‹•: http://0.0.0.0:5000
2025-09-05 00:27:50,953 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.64:5000
2025-09-05 00:27:50,953 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-05 00:27:51,949 - src.utils.ollama_utils - INFO - Attempting to fetch local models from Ollama service...
2025-09-05 00:27:51,958 - src.utils.ollama_utils - INFO - Received response from ollama.list(): models=[Model(model='qwen3:30b-a3b', modified_at=datetime.datetime(2025, 8, 31, 12, 17, 35, 223433, tzinfo=TzInfo(+08:00)), digest='e50831eb2d919df6268f18bc3cec980d597ae27e98c3308f90a0ec4941b64f28', size=18556699301, details=ModelDetails(parent_model='', format='gguf', family='qwen3moe', families=['qwen3moe'], parameter_size='30.5B', quantization_level='Q4_K_M')), Model(model='gpt-oss:20b', modified_at=datetime.datetime(2025, 8, 24, 8, 42, 55, 8404, tzinfo=TzInfo(+08:00)), digest='aa4295ac10c3afb60e6d711289fc6896f5aef82258997b9efdaed6d0cc4cd8b8', size=13780173724, details=ModelDetails(parent_model='', format='gguf', family='gptoss', families=['gptoss'], parameter_size='20.9B', quantization_level='MXFP4')), Model(model='gemma3:4b', modified_at=datetime.datetime(2025, 8, 20, 23, 55, 2, 564934, tzinfo=TzInfo(+08:00)), digest='a2af6cc3eb7fa8be8504abaf9b04e88f17a119ec3f04a3addf55f92841195f5a', size=3338801804, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='4.3B', quantization_level='Q4_K_M'))]
2025-09-05 00:27:51,958 - src.ui.web_interface - INFO - Broadcasting available_models event with data: {'models': ['qwen3:30b-a3b', 'gpt-oss:20b', 'gemma3:4b']}
2025-09-05 00:27:54,902 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:27:54] "GET / HTTP/1.1" 200 -
2025-09-05 00:27:55,161 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:27:55] "GET /socket.io/?EIO=4&transport=polling&t=PaLZbkM HTTP/1.1" 200 -
2025-09-05 00:27:55,185 - src.ui.web_interface - INFO - Web UI å®¢æˆ¶ç«¯å·²é€£æ¥
2025-09-05 00:27:55,185 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:27:55] "POST /socket.io/?EIO=4&transport=polling&t=PaLZbkj&sid=Ioq8V8KC7SlBlJBfAAAA HTTP/1.1" 200 -
2025-09-05 00:27:55,186 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:27:55] "GET /socket.io/?EIO=4&transport=polling&t=PaLZbkk&sid=Ioq8V8KC7SlBlJBfAAAA HTTP/1.1" 200 -
2025-09-05 00:27:55,217 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:27:55] "GET /socket.io/?EIO=4&transport=polling&t=PaLZblC&sid=Ioq8V8KC7SlBlJBfAAAA HTTP/1.1" 200 -
2025-09-05 00:28:01,493 - src.utils.ollama_utils - INFO - Attempting to fetch local models from Ollama service...
2025-09-05 00:28:01,498 - src.utils.ollama_utils - INFO - Received response from ollama.list(): models=[Model(model='qwen3:30b-a3b', modified_at=datetime.datetime(2025, 8, 31, 12, 17, 35, 223433, tzinfo=TzInfo(+08:00)), digest='e50831eb2d919df6268f18bc3cec980d597ae27e98c3308f90a0ec4941b64f28', size=18556699301, details=ModelDetails(parent_model='', format='gguf', family='qwen3moe', families=['qwen3moe'], parameter_size='30.5B', quantization_level='Q4_K_M')), Model(model='gpt-oss:20b', modified_at=datetime.datetime(2025, 8, 24, 8, 42, 55, 8404, tzinfo=TzInfo(+08:00)), digest='aa4295ac10c3afb60e6d711289fc6896f5aef82258997b9efdaed6d0cc4cd8b8', size=13780173724, details=ModelDetails(parent_model='', format='gguf', family='gptoss', families=['gptoss'], parameter_size='20.9B', quantization_level='MXFP4')), Model(model='gemma3:4b', modified_at=datetime.datetime(2025, 8, 20, 23, 55, 2, 564934, tzinfo=TzInfo(+08:00)), digest='a2af6cc3eb7fa8be8504abaf9b04e88f17a119ec3f04a3addf55f92841195f5a', size=3338801804, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='4.3B', quantization_level='Q4_K_M'))]
2025-09-05 00:28:01,499 - src.core.enhanced_tuner - INFO - å¢å¼·èª¿æ ¡å™¨å·²åˆå§‹åŒ–: gemma3:4b
2025-09-05 00:28:01,499 - src.core.enhanced_tuner - INFO - é–‹å§‹ç‚ºæ¨¡å‹ 'gemma3:4b' é€²è¡Œå¢å¼·èª¿æ ¡
2025-09-05 00:28:01,499 - src.core.enhanced_tuner - INFO - é–‹å§‹è²è‘‰æ–¯å„ªåŒ–å“è³ªèª¿æ ¡
2025-09-05 00:28:01,500 - src.core.enhanced_tuner - INFO - è¿­ä»£ 1/25: æ¸¬è©¦åƒæ•¸ {'temperature': 1.0226470850179432, 'top_p': 0.6769773456172155, 'top_k': 39.15492399714034}
2025-09-05 00:28:01,500 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 1.0226470850179432, 'top_p': 0.6769773456172155, 'top_k': 39.15492399714034}
2025-09-05 00:28:01,503 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:28:25,409 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:28:48,105 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:28:48,106 - src.models.bayesian_optimizer - INFO - ç™¼ç¾æ–°çš„æœ€ä½³çµæœ: 0.3302 with params: {'temperature': 1.0226470850179432, 'top_p': 0.6769773456172155, 'top_k': 39.15492399714034}
2025-09-05 00:28:48,106 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3302
2025-09-05 00:28:48,106 - src.core.enhanced_tuner - INFO - è¿­ä»£ 2/25: æ¸¬è©¦åƒæ•¸ {'temperature': 0.7196814662695036, 'top_p': 0.9584961260292273, 'top_k': 15.509842273236206}
2025-09-05 00:28:48,106 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 0.7196814662695036, 'top_p': 0.9584961260292273, 'top_k': 15.509842273236206}
2025-09-05 00:28:48,108 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:29:15,421 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:29:28,616 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:29:28,616 - src.models.bayesian_optimizer - INFO - ç™¼ç¾æ–°çš„æœ€ä½³çµæœ: 0.3362 with params: {'temperature': 0.7196814662695036, 'top_p': 0.9584961260292273, 'top_k': 15.509842273236206}
2025-09-05 00:29:28,621 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3362
2025-09-05 00:29:28,622 - src.core.enhanced_tuner - INFO - è¿­ä»£ 3/25: æ¸¬è©¦åƒæ•¸ {'temperature': 1.390968109299511, 'top_p': 0.9061353314914025, 'top_k': 128.77300414916442}
2025-09-05 00:29:28,622 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 1.390968109299511, 'top_p': 0.9061353314914025, 'top_k': 128.77300414916442}
2025-09-05 00:29:28,623 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:29:52,531 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:30:14,879 - __main__ - INFO - æ¥æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œæ­£åœ¨é—œé–‰...
2025-09-05 00:30:16,161 - src.utils.memory_monitor - INFO - è¨˜æ†¶é«”ç›£æ§å·²åœæ­¢
2025-09-05 00:30:16,161 - __main__ - INFO - ç¨‹å¼åŸ·è¡Œå®Œæˆ
2025-09-05 00:31:17,652 - src.ui.web_interface - INFO - Web UI å®¢æˆ¶ç«¯å·²æ–·é–‹
2025-09-05 00:31:17,652 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:31:17] "GET /socket.io/?EIO=4&transport=websocket&sid=Ioq8V8KC7SlBlJBfAAAA HTTP/1.1" 200 -
2025-09-05 00:35:40,238 - src.utils.memory_monitor - INFO - è¨˜æ†¶é«”ç›£æ§å·²å•Ÿå‹•
2025-09-05 00:35:40,239 - __main__ - INFO - ğŸŒ Web UI å·²å•Ÿå‹•: http://0.0.0.0:5000
2025-09-05 00:35:40,249 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.64:5000
2025-09-05 00:35:40,249 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-05 00:35:41,240 - src.utils.ollama_utils - INFO - Attempting to fetch local models from Ollama service...
2025-09-05 00:35:41,250 - src.utils.ollama_utils - INFO - Received response from ollama.list(): models=[Model(model='qwen3:30b-a3b', modified_at=datetime.datetime(2025, 8, 31, 12, 17, 35, 223433, tzinfo=TzInfo(+08:00)), digest='e50831eb2d919df6268f18bc3cec980d597ae27e98c3308f90a0ec4941b64f28', size=18556699301, details=ModelDetails(parent_model='', format='gguf', family='qwen3moe', families=['qwen3moe'], parameter_size='30.5B', quantization_level='Q4_K_M')), Model(model='gpt-oss:20b', modified_at=datetime.datetime(2025, 8, 24, 8, 42, 55, 8404, tzinfo=TzInfo(+08:00)), digest='aa4295ac10c3afb60e6d711289fc6896f5aef82258997b9efdaed6d0cc4cd8b8', size=13780173724, details=ModelDetails(parent_model='', format='gguf', family='gptoss', families=['gptoss'], parameter_size='20.9B', quantization_level='MXFP4')), Model(model='gemma3:4b', modified_at=datetime.datetime(2025, 8, 20, 23, 55, 2, 564934, tzinfo=TzInfo(+08:00)), digest='a2af6cc3eb7fa8be8504abaf9b04e88f17a119ec3f04a3addf55f92841195f5a', size=3338801804, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='4.3B', quantization_level='Q4_K_M'))]
2025-09-05 00:35:41,250 - src.ui.web_interface - INFO - Broadcasting available_models event with data: {'models': ['qwen3:30b-a3b', 'gpt-oss:20b', 'gemma3:4b']}
2025-09-05 00:35:43,207 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:35:43] "GET / HTTP/1.1" 200 -
2025-09-05 00:35:43,499 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:35:43] "GET /socket.io/?EIO=4&transport=polling&t=PaLbO47 HTTP/1.1" 200 -
2025-09-05 00:35:43,509 - src.ui.web_interface - INFO - Web UI å®¢æˆ¶ç«¯å·²é€£æ¥
2025-09-05 00:35:43,509 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:35:43] "POST /socket.io/?EIO=4&transport=polling&t=PaLbO4H&sid=G2L0_byiRMoYIk01AAAA HTTP/1.1" 200 -
2025-09-05 00:35:43,510 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:35:43] "GET /socket.io/?EIO=4&transport=polling&t=PaLbO4H.0&sid=G2L0_byiRMoYIk01AAAA HTTP/1.1" 200 -
2025-09-05 00:35:43,530 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:35:43] "GET /socket.io/?EIO=4&transport=polling&t=PaLbO4b&sid=G2L0_byiRMoYIk01AAAA HTTP/1.1" 200 -
2025-09-05 00:35:46,949 - src.utils.ollama_utils - INFO - Attempting to fetch local models from Ollama service...
2025-09-05 00:35:46,953 - src.utils.ollama_utils - INFO - Received response from ollama.list(): models=[Model(model='qwen3:30b-a3b', modified_at=datetime.datetime(2025, 8, 31, 12, 17, 35, 223433, tzinfo=TzInfo(+08:00)), digest='e50831eb2d919df6268f18bc3cec980d597ae27e98c3308f90a0ec4941b64f28', size=18556699301, details=ModelDetails(parent_model='', format='gguf', family='qwen3moe', families=['qwen3moe'], parameter_size='30.5B', quantization_level='Q4_K_M')), Model(model='gpt-oss:20b', modified_at=datetime.datetime(2025, 8, 24, 8, 42, 55, 8404, tzinfo=TzInfo(+08:00)), digest='aa4295ac10c3afb60e6d711289fc6896f5aef82258997b9efdaed6d0cc4cd8b8', size=13780173724, details=ModelDetails(parent_model='', format='gguf', family='gptoss', families=['gptoss'], parameter_size='20.9B', quantization_level='MXFP4')), Model(model='gemma3:4b', modified_at=datetime.datetime(2025, 8, 20, 23, 55, 2, 564934, tzinfo=TzInfo(+08:00)), digest='a2af6cc3eb7fa8be8504abaf9b04e88f17a119ec3f04a3addf55f92841195f5a', size=3338801804, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='4.3B', quantization_level='Q4_K_M'))]
2025-09-05 00:35:46,953 - src.core.enhanced_tuner - INFO - å¢å¼·èª¿æ ¡å™¨å·²åˆå§‹åŒ–: gemma3:4b
2025-09-05 00:35:46,953 - src.core.enhanced_tuner - INFO - é–‹å§‹ç‚ºæ¨¡å‹ 'gemma3:4b' é€²è¡Œå¢å¼·èª¿æ ¡
2025-09-05 00:35:46,953 - src.core.enhanced_tuner - INFO - é–‹å§‹è²è‘‰æ–¯å„ªåŒ–å“è³ªèª¿æ ¡
2025-09-05 00:35:46,954 - src.core.enhanced_tuner - INFO - è¿­ä»£ 1/25: æ¸¬è©¦åƒæ•¸ {'temperature': 0.5075234591421423, 'top_p': 0.8708267748341503, 'top_k': 116.86398401508619}
2025-09-05 00:35:46,954 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 0.5075234591421423, 'top_p': 0.8708267748341503, 'top_k': 116.86398401508619}
2025-09-05 00:35:46,971 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:35:54,016 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:36:08,616 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:36:08,616 - src.models.bayesian_optimizer - INFO - ç™¼ç¾æ–°çš„æœ€ä½³çµæœ: 0.3471 with params: {'temperature': 0.5075234591421423, 'top_p': 0.8708267748341503, 'top_k': 116.86398401508619}
2025-09-05 00:36:08,616 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3471
2025-09-05 00:36:08,616 - src.core.enhanced_tuner - INFO - è¿­ä»£ 2/25: æ¸¬è©¦åƒæ•¸ {'temperature': 0.9575678842633343, 'top_p': 0.82676906296067, 'top_k': 8.745266275630472}
2025-09-05 00:36:08,616 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 0.9575678842633343, 'top_p': 0.82676906296067, 'top_k': 8.745266275630472}
2025-09-05 00:36:08,618 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:36:13,934 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:36:28,933 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:36:28,938 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3319
2025-09-05 00:36:28,939 - src.core.enhanced_tuner - INFO - è¿­ä»£ 3/25: æ¸¬è©¦åƒæ•¸ {'temperature': 0.11739526470153593, 'top_p': 0.7808374140482071, 'top_k': 7.422648473428614}
2025-09-05 00:36:28,939 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 0.11739526470153593, 'top_p': 0.7808374140482071, 'top_k': 7.422648473428614}
2025-09-05 00:36:28,941 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:36:35,210 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:36:49,793 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:36:49,805 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3346
2025-09-05 00:36:49,805 - src.core.enhanced_tuner - INFO - è¿­ä»£ 4/25: æ¸¬è©¦åƒæ•¸ {'temperature': 0.4891286846068498, 'top_p': 0.8566160798193179, 'top_k': 134.29243891212852}
2025-09-05 00:36:49,805 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 0.4891286846068498, 'top_p': 0.8566160798193179, 'top_k': 134.29243891212852}
2025-09-05 00:36:49,807 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:36:55,737 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:37:10,266 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:37:10,272 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3294
2025-09-05 00:37:10,272 - src.core.enhanced_tuner - INFO - è¿­ä»£ 5/25: æ¸¬è©¦åƒæ•¸ {'temperature': 0.9954496464211967, 'top_p': 0.7820137069515722, 'top_k': 21.851143406052774}
2025-09-05 00:37:10,272 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 0.9954496464211967, 'top_p': 0.7820137069515722, 'top_k': 21.851143406052774}
2025-09-05 00:37:10,274 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:37:15,986 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:37:30,354 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:37:30,354 - src.models.bayesian_optimizer - INFO - ç™¼ç¾æ–°çš„æœ€ä½³çµæœ: 0.3744 with params: {'temperature': 0.9954496464211967, 'top_p': 0.7820137069515722, 'top_k': 21.851143406052774}
2025-09-05 00:37:30,367 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3744
2025-09-05 00:37:30,367 - src.core.enhanced_tuner - INFO - è¿­ä»£ 6/25: æ¸¬è©¦åƒæ•¸ {'temperature': 1.0740378923947573, 'top_p': 0.6994548131366124, 'top_k': 145.40518469091913}
2025-09-05 00:37:30,367 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 1.0740378923947573, 'top_p': 0.6994548131366124, 'top_k': 145.40518469091913}
2025-09-05 00:37:30,372 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:37:36,098 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:37:50,631 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:37:50,631 - src.models.bayesian_optimizer - INFO - ç™¼ç¾æ–°çš„æœ€ä½³çµæœ: 0.3829 with params: {'temperature': 1.0740378923947573, 'top_p': 0.6994548131366124, 'top_k': 145.40518469091913}
2025-09-05 00:37:50,664 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3829
2025-09-05 00:37:50,665 - src.core.enhanced_tuner - INFO - è¿­ä»£ 7/25: æ¸¬è©¦åƒæ•¸ {'temperature': 1.2789950317768497, 'top_p': 0.5460722868139163, 'top_k': 65.49518932754387}
2025-09-05 00:37:50,665 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 1.2789950317768497, 'top_p': 0.5460722868139163, 'top_k': 65.49518932754387}
2025-09-05 00:37:50,668 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:37:56,470 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:38:10,957 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:38:10,968 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3389
2025-09-05 00:38:10,968 - src.core.enhanced_tuner - INFO - è¿­ä»£ 8/25: æ¸¬è©¦åƒæ•¸ {'temperature': 0.6773879003167651, 'top_p': 0.5494772688242187, 'top_k': 144.13621487116316}
2025-09-05 00:38:10,969 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 0.6773879003167651, 'top_p': 0.5494772688242187, 'top_k': 144.13621487116316}
2025-09-05 00:38:10,973 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:38:17,002 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:38:31,656 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:38:31,666 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3364
2025-09-05 00:38:31,824 - src.core.enhanced_tuner - INFO - è¿­ä»£ 9/25: æ¸¬è©¦åƒæ•¸ {'temperature': np.float64(0.5497757720141645), 'top_p': np.float64(0.8896846546332753), 'top_k': np.float64(116.82047438568961)}
2025-09-05 00:38:31,824 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': np.float64(0.5497757720141645), 'top_p': np.float64(0.8896846546332753), 'top_k': np.float64(116.82047438568961)}
2025-09-05 00:38:31,829 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:38:37,755 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:38:52,470 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:38:52,482 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3287
2025-09-05 00:38:52,630 - src.core.enhanced_tuner - INFO - è¿­ä»£ 10/25: æ¸¬è©¦åƒæ•¸ {'temperature': np.float64(1.0924716093426796), 'top_p': np.float64(0.6883327990582209), 'top_k': np.float64(150.0)}
2025-09-05 00:38:52,631 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': np.float64(1.0924716093426796), 'top_p': np.float64(0.6883327990582209), 'top_k': np.float64(150.0)}
2025-09-05 00:38:52,635 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:38:58,548 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:39:13,183 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:39:13,198 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3287
2025-09-05 00:39:13,198 - src.core.enhanced_tuner - INFO - è§¸ç™¼æ—©åœæ¢ä»¶
2025-09-05 00:39:13,199 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 1.0740378923947573, 'top_p': 0.6994548131366124, 'top_k': 145.40518469091913}
2025-09-05 00:39:13,202 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:39:18,404 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:39:32,794 - src.core.enhanced_tuner - INFO - æœ€ä½³å“è³ªè¨­å®š: {'temperature': 1.0740378923947573, 'top_p': 0.6994548131366124, 'top_k': 145.40518469091913} (è©•åˆ†: 0.3829)
2025-09-05 00:39:32,794 - src.core.enhanced_tuner - INFO - é–‹å§‹ä¸Šä¸‹æ–‡çª—å£èª¿æ ¡
2025-09-05 00:39:32,795 - src.core.enhanced_tuner - INFO - æ¸¬è©¦ num_ctx = 8192
2025-09-05 00:39:35,983 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:39:35,983 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=3.19s, TTFT=432ms, TPS=103.42
2025-09-05 00:39:35,984 - src.core.enhanced_tuner - INFO - æ‰¾åˆ°å¯æ¥å—çš„ num_ctx: 8192
2025-09-05 00:39:35,984 - src.core.enhanced_tuner - INFO - é–‹å§‹ GPU å±¤æ•¸èª¿æ ¡
2025-09-05 00:39:35,985 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 50
2025-09-05 00:39:40,947 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:39:40,947 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=4.96s, TTFT=2332ms, TPS=104.94
2025-09-05 00:39:40,947 - src.core.enhanced_tuner - INFO - å¤±æ•—ï¼Œå˜—è©¦æ›´ä½å€¼
2025-09-05 00:39:40,949 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 24
2025-09-05 00:39:53,180 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:39:53,180 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=12.23s, TTFT=4469ms, TPS=35.32
2025-09-05 00:39:53,180 - src.core.enhanced_tuner - INFO - å¤±æ•—ï¼Œå˜—è©¦æ›´ä½å€¼
2025-09-05 00:39:53,180 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 11
2025-09-05 00:40:18,467 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:40:18,467 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=25.29s, TTFT=12640ms, TPS=24.67
2025-09-05 00:40:18,467 - src.core.enhanced_tuner - INFO - å¤±æ•—ï¼Œå˜—è©¦æ›´ä½å€¼
2025-09-05 00:40:18,468 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 5
2025-09-05 00:40:44,511 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:40:44,511 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=26.04s, TTFT=14107ms, TPS=22.62
2025-09-05 00:40:44,511 - src.core.enhanced_tuner - INFO - å¤±æ•—ï¼Œå˜—è©¦æ›´ä½å€¼
2025-09-05 00:40:44,512 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 2
2025-09-05 00:41:16,285 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:41:16,286 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=31.77s, TTFT=14819ms, TPS=17.81
2025-09-05 00:41:16,286 - src.core.enhanced_tuner - INFO - å¤±æ•—ï¼Œå˜—è©¦æ›´ä½å€¼
2025-09-05 00:41:16,286 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 1
2025-09-05 00:41:45,993 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:41:45,993 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=29.71s, TTFT=14924ms, TPS=19.62
2025-09-05 00:41:45,994 - src.core.enhanced_tuner - INFO - å¤±æ•—ï¼Œå˜—è©¦æ›´ä½å€¼
2025-09-05 00:42:15,000 - src.core.enhanced_tuner - WARNING - æœ€çµ‚ç¢ºèªå¤±æ•—ï¼Œä½¿ç”¨ CPU
2025-09-05 00:42:37,125 - src.core.enhanced_tuner - INFO - å¢å¼·èª¿æ ¡å®Œæˆ
2025-09-05 00:42:37,523 - src.utils.memory_monitor - INFO - è¨˜æ†¶é«”ç›£æ§å·²åœæ­¢
2025-09-05 00:42:37,523 - __main__ - ERROR - èª¿æ ¡éç¨‹ä¸­ç™¼ç”Ÿåš´é‡éŒ¯èª¤
Traceback (most recent call last):
  File "C:\Users\HOME\Desktop\LLM-Bench-main\web_ollama_autotuner.py", line 158, in run_tuning_logic
    if result and result != "incompatible": self.all_results.append(result); self.web_ui.add_tuning_result(result)
                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HOME\Desktop\LLM-Bench-main\src\ui\web_interface.py", line 115, in add_tuning_result
    self.socketio.emit('new_result', result)
  File "C:\Users\HOME\AppData\Local\Programs\Python\Python311\Lib\site-packages\flask_socketio\__init__.py", line 472, in emit
    self.server.emit(event, *args, namespace=namespace, to=to,
  File "C:\Users\HOME\AppData\Local\Programs\Python\Python311\Lib\site-packages\socketio\server.py", line 166, in emit
    self.manager.emit(event, data, namespace, room=room,
  File "C:\Users\HOME\AppData\Local\Programs\Python\Python311\Lib\site-packages\socketio\manager.py", line 44, in emit
    encoded_packet = pkt.encode()
                     ^^^^^^^^^^^^
  File "C:\Users\HOME\AppData\Local\Programs\Python\Python311\Lib\site-packages\socketio\packet.py", line 64, in encode
    encoded_packet += self.json.dumps(data, separators=(',', ':'))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HOME\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "C:\Users\HOME\AppData\Local\Programs\Python\Python311\Lib\json\encoder.py", line 200, in encode
    chunks = self.iterencode(o, _one_shot=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HOME\AppData\Local\Programs\Python\Python311\Lib\json\encoder.py", line 258, in iterencode
    return _iterencode(o, 0)
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\HOME\AppData\Local\Programs\Python\Python311\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type bool is not JSON serializable
2025-09-05 00:47:13,559 - __main__ - INFO - æ¥æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œæ­£åœ¨é—œé–‰...
2025-09-05 00:47:13,560 - src.utils.memory_monitor - INFO - è¨˜æ†¶é«”ç›£æ§å·²åœæ­¢
2025-09-05 00:47:13,560 - __main__ - INFO - ç¨‹å¼åŸ·è¡Œå®Œæˆ
2025-09-05 00:47:34,034 - src.utils.memory_monitor - INFO - è¨˜æ†¶é«”ç›£æ§å·²å•Ÿå‹•
2025-09-05 00:47:34,035 - __main__ - INFO - ğŸŒ Web UI å·²å•Ÿå‹•: http://0.0.0.0:5000
2025-09-05 00:47:34,043 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.64:5000
2025-09-05 00:47:34,043 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-05 00:47:35,037 - src.utils.ollama_utils - INFO - Attempting to fetch local models from Ollama service...
2025-09-05 00:47:35,042 - src.utils.ollama_utils - INFO - Received response from ollama.list(): models=[Model(model='qwen3:30b-a3b', modified_at=datetime.datetime(2025, 8, 31, 12, 17, 35, 223433, tzinfo=TzInfo(+08:00)), digest='e50831eb2d919df6268f18bc3cec980d597ae27e98c3308f90a0ec4941b64f28', size=18556699301, details=ModelDetails(parent_model='', format='gguf', family='qwen3moe', families=['qwen3moe'], parameter_size='30.5B', quantization_level='Q4_K_M')), Model(model='gpt-oss:20b', modified_at=datetime.datetime(2025, 8, 24, 8, 42, 55, 8404, tzinfo=TzInfo(+08:00)), digest='aa4295ac10c3afb60e6d711289fc6896f5aef82258997b9efdaed6d0cc4cd8b8', size=13780173724, details=ModelDetails(parent_model='', format='gguf', family='gptoss', families=['gptoss'], parameter_size='20.9B', quantization_level='MXFP4')), Model(model='gemma3:4b', modified_at=datetime.datetime(2025, 8, 20, 23, 55, 2, 564934, tzinfo=TzInfo(+08:00)), digest='a2af6cc3eb7fa8be8504abaf9b04e88f17a119ec3f04a3addf55f92841195f5a', size=3338801804, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='4.3B', quantization_level='Q4_K_M'))]
2025-09-05 00:47:35,042 - src.ui.web_interface - INFO - Broadcasting available_models event with data: {'models': ['qwen3:30b-a3b', 'gpt-oss:20b', 'gemma3:4b']}
2025-09-05 00:47:36,286 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:47:36] "GET / HTTP/1.1" 200 -
2025-09-05 00:47:36,565 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:47:36] "GET /socket.io/?EIO=4&transport=polling&t=PaLe69n HTTP/1.1" 200 -
2025-09-05 00:47:36,588 - src.ui.web_interface - INFO - Web UI å®¢æˆ¶ç«¯å·²é€£æ¥
2025-09-05 00:47:36,589 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:47:36] "POST /socket.io/?EIO=4&transport=polling&t=PaLe6A7&sid=VMq8300XPU1tnsXoAAAA HTTP/1.1" 200 -
2025-09-05 00:47:36,589 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:47:36] "GET /socket.io/?EIO=4&transport=polling&t=PaLe6A8&sid=VMq8300XPU1tnsXoAAAA HTTP/1.1" 200 -
2025-09-05 00:47:36,619 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:47:36] "GET /socket.io/?EIO=4&transport=polling&t=PaLe6Ac&sid=VMq8300XPU1tnsXoAAAA HTTP/1.1" 200 -
2025-09-05 00:47:41,582 - src.utils.ollama_utils - INFO - Attempting to fetch local models from Ollama service...
2025-09-05 00:47:41,588 - src.utils.ollama_utils - INFO - Received response from ollama.list(): models=[Model(model='qwen3:30b-a3b', modified_at=datetime.datetime(2025, 8, 31, 12, 17, 35, 223433, tzinfo=TzInfo(+08:00)), digest='e50831eb2d919df6268f18bc3cec980d597ae27e98c3308f90a0ec4941b64f28', size=18556699301, details=ModelDetails(parent_model='', format='gguf', family='qwen3moe', families=['qwen3moe'], parameter_size='30.5B', quantization_level='Q4_K_M')), Model(model='gpt-oss:20b', modified_at=datetime.datetime(2025, 8, 24, 8, 42, 55, 8404, tzinfo=TzInfo(+08:00)), digest='aa4295ac10c3afb60e6d711289fc6896f5aef82258997b9efdaed6d0cc4cd8b8', size=13780173724, details=ModelDetails(parent_model='', format='gguf', family='gptoss', families=['gptoss'], parameter_size='20.9B', quantization_level='MXFP4')), Model(model='gemma3:4b', modified_at=datetime.datetime(2025, 8, 20, 23, 55, 2, 564934, tzinfo=TzInfo(+08:00)), digest='a2af6cc3eb7fa8be8504abaf9b04e88f17a119ec3f04a3addf55f92841195f5a', size=3338801804, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='4.3B', quantization_level='Q4_K_M'))]
2025-09-05 00:47:41,589 - src.core.enhanced_tuner - INFO - å¢å¼·èª¿æ ¡å™¨å·²åˆå§‹åŒ–: gemma3:4b
2025-09-05 00:47:41,589 - src.core.enhanced_tuner - INFO - é–‹å§‹ç‚ºæ¨¡å‹ 'gemma3:4b' é€²è¡Œå¢å¼·èª¿æ ¡
2025-09-05 00:47:41,589 - src.core.enhanced_tuner - INFO - é–‹å§‹è²è‘‰æ–¯å„ªåŒ–å“è³ªèª¿æ ¡
2025-09-05 00:47:41,589 - src.core.enhanced_tuner - INFO - è¿­ä»£ 1/25: æ¸¬è©¦åƒæ•¸ {'temperature': 0.1406354562503433, 'top_p': 0.6314384092211157, 'top_k': 68.13655815827653}
2025-09-05 00:47:41,590 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 0.1406354562503433, 'top_p': 0.6314384092211157, 'top_k': 68.13655815827653}
2025-09-05 00:47:41,593 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:47:48,375 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:48:02,690 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:48:02,690 - src.models.bayesian_optimizer - INFO - ç™¼ç¾æ–°çš„æœ€ä½³çµæœ: 0.3396 with params: {'temperature': 0.1406354562503433, 'top_p': 0.6314384092211157, 'top_k': 68.13655815827653}
2025-09-05 00:48:02,690 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3396
2025-09-05 00:48:02,690 - src.core.enhanced_tuner - INFO - è¿­ä»£ 2/25: æ¸¬è©¦åƒæ•¸ {'temperature': 0.638572778767188, 'top_p': 0.5280618314345944, 'top_k': 54.03533399105622}
2025-09-05 00:48:02,690 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 0.638572778767188, 'top_p': 0.5280618314345944, 'top_k': 54.03533399105622}
2025-09-05 00:48:02,692 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:48:08,392 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:48:23,011 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:48:23,018 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3308
2025-09-05 00:48:23,018 - src.core.enhanced_tuner - INFO - è¿­ä»£ 3/25: æ¸¬è©¦åƒæ•¸ {'temperature': 1.0753286945907017, 'top_p': 0.8741195183695025, 'top_k': 36.37734709743246}
2025-09-05 00:48:23,019 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 1.0753286945907017, 'top_p': 0.8741195183695025, 'top_k': 36.37734709743246}
2025-09-05 00:48:23,020 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:48:28,650 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:48:42,924 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:48:42,924 - src.models.bayesian_optimizer - INFO - ç™¼ç¾æ–°çš„æœ€ä½³çµæœ: 0.3625 with params: {'temperature': 1.0753286945907017, 'top_p': 0.8741195183695025, 'top_k': 36.37734709743246}
2025-09-05 00:48:42,935 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3625
2025-09-05 00:48:42,936 - src.core.enhanced_tuner - INFO - è¿­ä»£ 4/25: æ¸¬è©¦åƒæ•¸ {'temperature': 0.5252277355266722, 'top_p': 0.8908362556548343, 'top_k': 58.01256633736893}
2025-09-05 00:48:42,936 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 0.5252277355266722, 'top_p': 0.8908362556548343, 'top_k': 58.01256633736893}
2025-09-05 00:48:42,938 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:48:48,617 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:49:02,895 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:49:02,903 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3364
2025-09-05 00:49:02,903 - src.core.enhanced_tuner - INFO - è¿­ä»£ 5/25: æ¸¬è©¦åƒæ•¸ {'temperature': 0.2956868585921255, 'top_p': 0.7768261149805669, 'top_k': 69.0547688906114}
2025-09-05 00:49:02,903 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 0.2956868585921255, 'top_p': 0.7768261149805669, 'top_k': 69.0547688906114}
2025-09-05 00:49:02,904 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:49:09,087 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:49:23,439 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:49:23,442 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3300
2025-09-05 00:49:23,443 - src.core.enhanced_tuner - INFO - è¿­ä»£ 6/25: æ¸¬è©¦åƒæ•¸ {'temperature': 0.7742942330013114, 'top_p': 0.8084434287871063, 'top_k': 95.73645690377329}
2025-09-05 00:49:23,443 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 0.7742942330013114, 'top_p': 0.8084434287871063, 'top_k': 95.73645690377329}
2025-09-05 00:49:23,445 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:49:28,998 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:49:43,254 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:49:43,262 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3306
2025-09-05 00:49:43,263 - src.core.enhanced_tuner - INFO - è¿­ä»£ 7/25: æ¸¬è©¦åƒæ•¸ {'temperature': 1.027578842218201, 'top_p': 0.6276950358328454, 'top_k': 26.503039636514725}
2025-09-05 00:49:43,263 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 1.027578842218201, 'top_p': 0.6276950358328454, 'top_k': 26.503039636514725}
2025-09-05 00:49:43,265 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:49:49,270 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:50:04,084 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:50:04,093 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3314
2025-09-05 00:50:04,093 - src.core.enhanced_tuner - INFO - è¿­ä»£ 8/25: æ¸¬è©¦åƒæ•¸ {'temperature': 0.4347794356396437, 'top_p': 0.5214979909287658, 'top_k': 9.588833595867658}
2025-09-05 00:50:04,093 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 0.4347794356396437, 'top_p': 0.5214979909287658, 'top_k': 9.588833595867658}
2025-09-05 00:50:04,095 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:50:09,915 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:50:24,351 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:50:24,354 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.3308
2025-09-05 00:50:24,355 - src.core.enhanced_tuner - INFO - è§¸ç™¼æ—©åœæ¢ä»¶
2025-09-05 00:50:24,355 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 1.0753286945907017, 'top_p': 0.8741195183695025, 'top_k': 36.37734709743246}
2025-09-05 00:50:24,356 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 00:50:29,955 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 00:50:44,269 - src.core.enhanced_tuner - INFO - æœ€ä½³å“è³ªè¨­å®š: {'temperature': 1.0753286945907017, 'top_p': 0.8741195183695025, 'top_k': 36.37734709743246} (è©•åˆ†: 0.3625)
2025-09-05 00:50:44,270 - src.core.enhanced_tuner - INFO - é–‹å§‹ä¸Šä¸‹æ–‡çª—å£èª¿æ ¡
2025-09-05 00:50:44,270 - src.core.enhanced_tuner - INFO - æ¸¬è©¦ num_ctx = 8192
2025-09-05 00:50:47,475 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:50:47,476 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=3.20s, TTFT=465ms, TPS=102.57
2025-09-05 00:50:47,476 - src.core.enhanced_tuner - INFO - æ‰¾åˆ°å¯æ¥å—çš„ num_ctx: 8192
2025-09-05 00:50:47,476 - src.core.enhanced_tuner - INFO - é–‹å§‹ GPU å±¤æ•¸èª¿æ ¡
2025-09-05 00:50:47,476 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 50
2025-09-05 00:50:52,199 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:50:52,199 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=4.72s, TTFT=2352ms, TPS=104.66
2025-09-05 00:50:52,199 - src.core.enhanced_tuner - INFO - å¤±æ•—ï¼Œå˜—è©¦æ›´ä½å€¼
2025-09-05 00:50:52,199 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 24
2025-09-05 00:51:05,074 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:51:05,074 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=12.87s, TTFT=4538ms, TPS=35.02
2025-09-05 00:51:05,074 - src.core.enhanced_tuner - INFO - å¤±æ•—ï¼Œå˜—è©¦æ›´ä½å€¼
2025-09-05 00:51:05,075 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 11
2025-09-05 00:51:30,534 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:51:30,534 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=25.46s, TTFT=12275ms, TPS=25.26
2025-09-05 00:51:30,534 - src.core.enhanced_tuner - INFO - å¤±æ•—ï¼Œå˜—è©¦æ›´ä½å€¼
2025-09-05 00:51:30,534 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 5
2025-09-05 00:51:54,433 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:51:54,433 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=23.90s, TTFT=13682ms, TPS=22.91
2025-09-05 00:51:54,433 - src.core.enhanced_tuner - INFO - å¤±æ•—ï¼Œå˜—è©¦æ›´ä½å€¼
2025-09-05 00:51:54,433 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 2
2025-09-05 00:52:22,463 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:52:22,463 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=28.03s, TTFT=14366ms, TPS=21.59
2025-09-05 00:52:22,463 - src.core.enhanced_tuner - INFO - å¤±æ•—ï¼Œå˜—è©¦æ›´ä½å€¼
2025-09-05 00:52:22,464 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 1
2025-09-05 00:52:50,403 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: gemma3:4b
2025-09-05 00:52:50,404 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=27.94s, TTFT=14576ms, TPS=21.03
2025-09-05 00:52:50,404 - src.core.enhanced_tuner - INFO - å¤±æ•—ï¼Œå˜—è©¦æ›´ä½å€¼
2025-09-05 00:53:22,120 - src.core.enhanced_tuner - WARNING - æœ€çµ‚ç¢ºèªå¤±æ•—ï¼Œä½¿ç”¨ CPU
2025-09-05 00:53:42,591 - src.core.enhanced_tuner - INFO - å¢å¼·èª¿æ ¡å®Œæˆ
2025-09-05 00:53:44,117 - src.utils.memory_monitor - INFO - è¨˜æ†¶é«”ç›£æ§å·²åœæ­¢
2025-09-05 00:54:20,264 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 00:54:20] "GET /enhanced_ollama_tuner_report.html HTTP/1.1" 200 -
2025-09-05 00:59:12,634 - __main__ - INFO - æ¥æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œæ­£åœ¨é—œé–‰...
2025-09-05 00:59:12,634 - src.utils.memory_monitor - INFO - è¨˜æ†¶é«”ç›£æ§å·²åœæ­¢
2025-09-05 00:59:12,634 - __main__ - INFO - ç¨‹å¼åŸ·è¡Œå®Œæˆ
2025-09-05 11:10:13,714 - src.utils.memory_monitor - INFO - è¨˜æ†¶é«”ç›£æ§å·²å•Ÿå‹•
2025-09-05 11:10:13,715 - __main__ - INFO - ğŸŒ Web UI å·²å•Ÿå‹•: http://0.0.0.0:5000
2025-09-05 11:10:13,725 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.8.21.24:5000
2025-09-05 11:10:13,725 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-05 11:10:14,716 - src.utils.ollama_utils - INFO - Attempting to fetch local models from Ollama service...
2025-09-05 11:10:14,723 - src.utils.ollama_utils - INFO - Received response from ollama.list(): models=[Model(model='qwen3:30b-a3b', modified_at=datetime.datetime(2025, 9, 1, 14, 45, 7, 865706, tzinfo=TzInfo(+08:00)), digest='e50831eb2d919df6268f18bc3cec980d597ae27e98c3308f90a0ec4941b64f28', size=18556699301, details=ModelDetails(parent_model='', format='gguf', family='qwen3moe', families=['qwen3moe'], parameter_size='30.5B', quantization_level='Q4_K_M')), Model(model='gemma3:4b', modified_at=datetime.datetime(2025, 8, 19, 19, 20, 58, 611103, tzinfo=TzInfo(+08:00)), digest='a2af6cc3eb7fa8be8504abaf9b04e88f17a119ec3f04a3addf55f92841195f5a', size=3338801804, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='4.3B', quantization_level='Q4_K_M')), Model(model='gpt-oss:20b', modified_at=datetime.datetime(2025, 8, 13, 10, 17, 23, 411869, tzinfo=TzInfo(+08:00)), digest='aa4295ac10c3afb60e6d711289fc6896f5aef82258997b9efdaed6d0cc4cd8b8', size=13780173724, details=ModelDetails(parent_model='', format='gguf', family='gptoss', families=['gptoss'], parameter_size='20.9B', quantization_level='MXFP4')), Model(model='nomic-embed-text:latest', modified_at=datetime.datetime(2025, 7, 18, 9, 38, 42, 93554, tzinfo=TzInfo(+08:00)), digest='0a109f422b47e3a30ba2b10eca18548e944e8a23073ee3f3e947efcf3c45e59f', size=274302450, details=ModelDetails(parent_model='', format='gguf', family='nomic-bert', families=['nomic-bert'], parameter_size='137M', quantization_level='F16'))]
2025-09-05 11:10:14,723 - src.ui.web_interface - INFO - Broadcasting available_models event with data: {'models': ['qwen3:30b-a3b', 'gemma3:4b', 'gpt-oss:20b', 'nomic-embed-text:latest']}
2025-09-05 11:10:15,658 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 11:10:15] "GET / HTTP/1.1" 200 -
2025-09-05 11:10:15,928 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 11:10:15] "GET /socket.io/?EIO=4&transport=polling&t=PaNsd5p HTTP/1.1" 200 -
2025-09-05 11:10:15,964 - src.ui.web_interface - INFO - Web UI å®¢æˆ¶ç«¯å·²é€£æ¥
2025-09-05 11:10:15,965 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 11:10:15] "POST /socket.io/?EIO=4&transport=polling&t=PaNsd6O&sid=yktFtOdff4XSQDV4AAAA HTTP/1.1" 200 -
2025-09-05 11:10:15,965 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 11:10:15] "GET /socket.io/?EIO=4&transport=polling&t=PaNsd6O.0&sid=yktFtOdff4XSQDV4AAAA HTTP/1.1" 200 -
2025-09-05 11:10:15,974 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 11:10:15] "GET /socket.io/?EIO=4&transport=polling&t=PaNsd6Z&sid=yktFtOdff4XSQDV4AAAA HTTP/1.1" 200 -
2025-09-05 11:10:18,966 - src.utils.ollama_utils - INFO - Attempting to fetch local models from Ollama service...
2025-09-05 11:10:18,969 - src.utils.ollama_utils - INFO - Received response from ollama.list(): models=[Model(model='qwen3:30b-a3b', modified_at=datetime.datetime(2025, 9, 1, 14, 45, 7, 865706, tzinfo=TzInfo(+08:00)), digest='e50831eb2d919df6268f18bc3cec980d597ae27e98c3308f90a0ec4941b64f28', size=18556699301, details=ModelDetails(parent_model='', format='gguf', family='qwen3moe', families=['qwen3moe'], parameter_size='30.5B', quantization_level='Q4_K_M')), Model(model='gemma3:4b', modified_at=datetime.datetime(2025, 8, 19, 19, 20, 58, 611103, tzinfo=TzInfo(+08:00)), digest='a2af6cc3eb7fa8be8504abaf9b04e88f17a119ec3f04a3addf55f92841195f5a', size=3338801804, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='4.3B', quantization_level='Q4_K_M')), Model(model='gpt-oss:20b', modified_at=datetime.datetime(2025, 8, 13, 10, 17, 23, 411869, tzinfo=TzInfo(+08:00)), digest='aa4295ac10c3afb60e6d711289fc6896f5aef82258997b9efdaed6d0cc4cd8b8', size=13780173724, details=ModelDetails(parent_model='', format='gguf', family='gptoss', families=['gptoss'], parameter_size='20.9B', quantization_level='MXFP4')), Model(model='nomic-embed-text:latest', modified_at=datetime.datetime(2025, 7, 18, 9, 38, 42, 93554, tzinfo=TzInfo(+08:00)), digest='0a109f422b47e3a30ba2b10eca18548e944e8a23073ee3f3e947efcf3c45e59f', size=274302450, details=ModelDetails(parent_model='', format='gguf', family='nomic-bert', families=['nomic-bert'], parameter_size='137M', quantization_level='F16'))]
2025-09-05 11:10:18,970 - src.core.enhanced_tuner - INFO - å¢å¼·èª¿æ ¡å™¨å·²åˆå§‹åŒ–: qwen3:30b-a3b
2025-09-05 11:10:18,970 - src.core.enhanced_tuner - INFO - é–‹å§‹ç‚ºæ¨¡å‹ 'qwen3:30b-a3b' é€²è¡Œå¢å¼·èª¿æ ¡
2025-09-05 11:10:18,970 - src.core.enhanced_tuner - INFO - é–‹å§‹è²è‘‰æ–¯å„ªåŒ–å“è³ªèª¿æ ¡
2025-09-05 11:10:18,971 - src.core.enhanced_tuner - INFO - è¿­ä»£ 1/25: æ¸¬è©¦åƒæ•¸ {'temperature': 1.4185055519381338, 'top_p': 0.9280650096649388, 'top_k': 100.42017032434809}
2025-09-05 11:10:18,971 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 1.4185055519381338, 'top_p': 0.9280650096649388, 'top_k': 100.42017032434809}
2025-09-05 11:10:18,973 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 11:12:28,502 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 11:12:53,208 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: qwen3:30b-a3b
2025-09-05 11:12:53,209 - src.models.bayesian_optimizer - INFO - ç™¼ç¾æ–°çš„æœ€ä½³çµæœ: 0.5016 with params: {'temperature': 1.4185055519381338, 'top_p': 0.9280650096649388, 'top_k': 100.42017032434809}
2025-09-05 11:12:53,209 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.5016
2025-09-05 11:12:53,209 - src.core.enhanced_tuner - INFO - è¿­ä»£ 2/25: æ¸¬è©¦åƒæ•¸ {'temperature': 0.6791907465683904, 'top_p': 0.7196908946705571, 'top_k': 54.65240896595049}
2025-09-05 11:12:53,209 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 0.6791907465683904, 'top_p': 0.7196908946705571, 'top_k': 54.65240896595049}
2025-09-05 11:12:53,211 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 11:14:02,723 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 11:14:53,711 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: qwen3:30b-a3b
2025-09-05 11:14:53,711 - src.models.bayesian_optimizer - INFO - ç™¼ç¾æ–°çš„æœ€ä½³çµæœ: 0.5174 with params: {'temperature': 0.6791907465683904, 'top_p': 0.7196908946705571, 'top_k': 54.65240896595049}
2025-09-05 11:14:53,716 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.5174
2025-09-05 11:14:53,717 - src.core.enhanced_tuner - INFO - è¿­ä»£ 3/25: æ¸¬è©¦åƒæ•¸ {'temperature': 1.3843717287623631, 'top_p': 0.8756120906630582, 'top_k': 117.50700883027694}
2025-09-05 11:14:53,717 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 1.3843717287623631, 'top_p': 0.8756120906630582, 'top_k': 117.50700883027694}
2025-09-05 11:14:53,718 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 11:16:12,618 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 11:17:14,120 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: qwen3:30b-a3b
2025-09-05 11:17:14,127 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.5162
2025-09-05 11:17:14,127 - src.core.enhanced_tuner - INFO - è¿­ä»£ 4/25: æ¸¬è©¦åƒæ•¸ {'temperature': 1.1141937590928348, 'top_p': 0.7833439793468415, 'top_k': 21.61876367826864}
2025-09-05 11:17:14,127 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 1.1141937590928348, 'top_p': 0.7833439793468415, 'top_k': 21.61876367826864}
2025-09-05 11:17:14,129 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 11:18:31,083 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 11:19:15,521 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: qwen3:30b-a3b
2025-09-05 11:19:15,521 - src.models.bayesian_optimizer - INFO - ç™¼ç¾æ–°çš„æœ€ä½³çµæœ: 0.5211 with params: {'temperature': 1.1141937590928348, 'top_p': 0.7833439793468415, 'top_k': 21.61876367826864}
2025-09-05 11:19:15,525 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.5211
2025-09-05 11:19:15,525 - src.core.enhanced_tuner - INFO - è¿­ä»£ 5/25: æ¸¬è©¦åƒæ•¸ {'temperature': 0.6327131312661468, 'top_p': 0.6935009063017723, 'top_k': 23.79883692734129}
2025-09-05 11:19:15,526 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 0.6327131312661468, 'top_p': 0.6935009063017723, 'top_k': 23.79883692734129}
2025-09-05 11:19:15,528 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 11:20:34,073 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 11:21:31,637 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: qwen3:30b-a3b
2025-09-05 11:21:31,642 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.5163
2025-09-05 11:21:31,642 - src.core.enhanced_tuner - INFO - è¿­ä»£ 6/25: æ¸¬è©¦åƒæ•¸ {'temperature': 1.1292759363871347, 'top_p': 0.6078777503764865, 'top_k': 142.25312717856866}
2025-09-05 11:21:31,642 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 1.1292759363871347, 'top_p': 0.6078777503764865, 'top_k': 142.25312717856866}
2025-09-05 11:21:31,644 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 11:23:06,521 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 11:23:35,825 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: qwen3:30b-a3b
2025-09-05 11:23:35,826 - src.models.bayesian_optimizer - INFO - ç™¼ç¾æ–°çš„æœ€ä½³çµæœ: 0.5563 with params: {'temperature': 1.1292759363871347, 'top_p': 0.6078777503764865, 'top_k': 142.25312717856866}
2025-09-05 11:23:35,831 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.5563
2025-09-05 11:23:35,831 - src.core.enhanced_tuner - INFO - è¿­ä»£ 7/25: æ¸¬è©¦åƒæ•¸ {'temperature': 1.017116934594749, 'top_p': 0.6287105491310268, 'top_k': 85.20487520161345}
2025-09-05 11:23:35,832 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 1.017116934594749, 'top_p': 0.6287105491310268, 'top_k': 85.20487520161345}
2025-09-05 11:23:35,834 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 11:24:58,485 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 11:25:55,878 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: qwen3:30b-a3b
2025-09-05 11:25:55,883 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.5159
2025-09-05 11:25:55,884 - src.core.enhanced_tuner - INFO - è¿­ä»£ 8/25: æ¸¬è©¦åƒæ•¸ {'temperature': 1.2563082245845432, 'top_p': 0.8559539765950248, 'top_k': 130.89886450857247}
2025-09-05 11:25:55,884 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': 1.2563082245845432, 'top_p': 0.8559539765950248, 'top_k': 130.89886450857247}
2025-09-05 11:25:55,886 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 11:27:10,023 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 11:28:02,254 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: qwen3:30b-a3b
2025-09-05 11:28:02,260 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.5142
2025-09-05 11:28:02,323 - src.core.enhanced_tuner - INFO - è¿­ä»£ 9/25: æ¸¬è©¦åƒæ•¸ {'temperature': np.float64(1.0519314342165633), 'top_p': np.float64(0.7789420229749019), 'top_k': np.float64(31.801975928752864)}
2025-09-05 11:28:02,324 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': np.float64(1.0519314342165633), 'top_p': np.float64(0.7789420229749019), 'top_k': np.float64(31.801975928752864)}
2025-09-05 11:28:02,326 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 11:29:38,229 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 11:30:28,761 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: qwen3:30b-a3b
2025-09-05 11:30:28,767 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.5058
2025-09-05 11:30:28,823 - src.core.enhanced_tuner - INFO - è¿­ä»£ 10/25: æ¸¬è©¦åƒæ•¸ {'temperature': np.float64(1.1325911052245488), 'top_p': np.float64(0.594428403065114), 'top_k': np.float64(93.70937477544715)}
2025-09-05 11:30:28,823 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': np.float64(1.1325911052245488), 'top_p': np.float64(0.594428403065114), 'top_k': np.float64(93.70937477544715)}
2025-09-05 11:30:28,825 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 11:31:55,306 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 11:32:59,040 - src.ui.web_interface - INFO - Web UI å®¢æˆ¶ç«¯å·²æ–·é–‹
2025-09-05 11:32:59,040 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 11:32:59] "GET /socket.io/?EIO=4&transport=websocket&sid=yktFtOdff4XSQDV4AAAA HTTP/1.1" 200 -
2025-09-05 11:32:59,799 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: qwen3:30b-a3b
2025-09-05 11:32:59,806 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.5219
2025-09-05 11:32:59,858 - src.core.enhanced_tuner - INFO - è¿­ä»£ 11/25: æ¸¬è©¦åƒæ•¸ {'temperature': np.float64(1.0857121772919542), 'top_p': np.float64(0.585732901998774), 'top_k': np.float64(99.20452349194485)}
2025-09-05 11:32:59,859 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': np.float64(1.0857121772919542), 'top_p': np.float64(0.585732901998774), 'top_k': np.float64(99.20452349194485)}
2025-09-05 11:32:59,860 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 11:33:00,128 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 11:33:00] "GET /socket.io/?EIO=4&transport=polling&t=PaNxq9Q HTTP/1.1" 200 -
2025-09-05 11:33:00,134 - src.ui.web_interface - INFO - Web UI å®¢æˆ¶ç«¯å·²é€£æ¥
2025-09-05 11:33:00,134 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 11:33:00] "POST /socket.io/?EIO=4&transport=polling&t=PaNxq9Y&sid=_v0UpTB6Z9V8w5NtAAAC HTTP/1.1" 200 -
2025-09-05 11:33:00,136 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 11:33:00] "GET /socket.io/?EIO=4&transport=polling&t=PaNxq9Z&sid=_v0UpTB6Z9V8w5NtAAAC HTTP/1.1" 200 -
2025-09-05 11:33:00,143 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 11:33:00] "GET /socket.io/?EIO=4&transport=polling&t=PaNxq9i&sid=_v0UpTB6Z9V8w5NtAAAC HTTP/1.1" 200 -
2025-09-05 11:34:10,462 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 11:34:49,588 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: qwen3:30b-a3b
2025-09-05 11:34:49,588 - src.models.bayesian_optimizer - INFO - ç™¼ç¾æ–°çš„æœ€ä½³çµæœ: 0.5580 with params: {'temperature': np.float64(1.0857121772919542), 'top_p': np.float64(0.585732901998774), 'top_k': np.float64(99.20452349194485)}
2025-09-05 11:34:49,594 - src.core.enhanced_tuner - INFO - è©•åˆ†: 0.5580
2025-09-05 11:34:49,594 - src.core.enhanced_tuner - INFO - è§¸ç™¼æ—©åœæ¢ä»¶
2025-09-05 11:34:49,594 - src.core.enhanced_tuner - INFO - é–‹å§‹å°è¨­å®šé€²è¡Œå…¨é¢å“è³ªè©•ä¼°: {'temperature': np.float64(1.0857121772919542), 'top_p': np.float64(0.585732901998774), 'top_k': np.float64(99.20452349194485)}
2025-09-05 11:34:49,596 - src.core.enhanced_tuner - INFO - å·²åŠ å…¥ HumanEval å•é¡Œ 'HumanEval/0' é€²è¡Œè©•ä¼°ã€‚
2025-09-05 11:36:02,731 - src.core.new_enhanced_evaluator - WARNING - ROUGE/BLEU æŒ‡æ¨™ä¸å¯ç”¨ï¼Œè·³éæ‘˜è¦è©•ä¼°ã€‚
2025-09-05 11:36:39,768 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 11:36:39] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
2025-09-05 11:37:21,182 - src.core.enhanced_tuner - INFO - æœ€ä½³å“è³ªè¨­å®š: {'temperature': np.float64(1.0857121772919542), 'top_p': np.float64(0.585732901998774), 'top_k': np.float64(99.20452349194485)} (è©•åˆ†: 0.5580)
2025-09-05 11:37:21,183 - src.core.enhanced_tuner - INFO - é–‹å§‹ä¸Šä¸‹æ–‡çª—å£èª¿æ ¡
2025-09-05 11:37:21,183 - src.core.enhanced_tuner - INFO - æ¸¬è©¦ num_ctx = 8192
2025-09-05 11:37:42,525 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: qwen3:30b-a3b
2025-09-05 11:37:42,526 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=21.34s, TTFT=4522ms, TPS=113.50
2025-09-05 11:37:42,526 - src.core.enhanced_tuner - INFO - æ‰¾åˆ°å¯æ¥å—çš„ num_ctx: 8192
2025-09-05 11:37:42,526 - src.core.enhanced_tuner - INFO - é–‹å§‹ GPU å±¤æ•¸èª¿æ ¡
2025-09-05 11:37:42,526 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 50
2025-09-05 11:38:01,591 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: qwen3:30b-a3b
2025-09-05 11:38:01,591 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=19.06s, TTFT=4626ms, TPS=114.63
2025-09-05 11:38:01,591 - src.core.enhanced_tuner - INFO - æˆåŠŸï¼Œå˜—è©¦æ›´é«˜å€¼
2025-09-05 11:38:01,592 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 75
2025-09-05 11:38:22,185 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: qwen3:30b-a3b
2025-09-05 11:38:22,185 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=20.59s, TTFT=4668ms, TPS=112.73
2025-09-05 11:38:22,185 - src.core.enhanced_tuner - INFO - æˆåŠŸï¼Œå˜—è©¦æ›´é«˜å€¼
2025-09-05 11:38:22,185 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 88
2025-09-05 11:38:41,543 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: qwen3:30b-a3b
2025-09-05 11:38:41,543 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=19.35s, TTFT=4563ms, TPS=114.33
2025-09-05 11:38:41,543 - src.core.enhanced_tuner - INFO - æˆåŠŸï¼Œå˜—è©¦æ›´é«˜å€¼
2025-09-05 11:38:41,544 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 94
2025-09-05 11:39:01,098 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: qwen3:30b-a3b
2025-09-05 11:39:01,098 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=19.55s, TTFT=4557ms, TPS=113.70
2025-09-05 11:39:01,099 - src.core.enhanced_tuner - INFO - æˆåŠŸï¼Œå˜—è©¦æ›´é«˜å€¼
2025-09-05 11:39:01,099 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 97
2025-09-05 11:39:22,532 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: qwen3:30b-a3b
2025-09-05 11:39:22,532 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=21.43s, TTFT=4640ms, TPS=113.09
2025-09-05 11:39:22,532 - src.core.enhanced_tuner - INFO - æˆåŠŸï¼Œå˜—è©¦æ›´é«˜å€¼
2025-09-05 11:39:22,532 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 99
2025-09-05 11:39:43,297 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: qwen3:30b-a3b
2025-09-05 11:39:43,298 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=20.76s, TTFT=4573ms, TPS=113.65
2025-09-05 11:39:43,298 - src.core.enhanced_tuner - INFO - æˆåŠŸï¼Œå˜—è©¦æ›´é«˜å€¼
2025-09-05 11:39:43,298 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 100
2025-09-05 11:40:07,077 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: qwen3:30b-a3b
2025-09-05 11:40:07,077 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=23.78s, TTFT=4591ms, TPS=112.68
2025-09-05 11:40:07,078 - src.core.enhanced_tuner - INFO - æˆåŠŸï¼Œå˜—è©¦æ›´é«˜å€¼
2025-09-05 11:40:07,078 - src.core.enhanced_tuner - INFO - äºŒåˆ†æœå°‹æ¸¬è©¦ num_gpu = 101
2025-09-05 11:40:27,998 - src.utils.cache_manager - INFO - ç·©å­˜çµæœå·²ä¿å­˜: qwen3:30b-a3b
2025-09-05 11:40:27,998 - src.core.enhanced_tuner - INFO - æ€§èƒ½: ç¸½æ™‚é–“=20.92s, TTFT=4611ms, TPS=112.03
2025-09-05 11:40:27,999 - src.core.enhanced_tuner - INFO - æˆåŠŸï¼Œå˜—è©¦æ›´é«˜å€¼
2025-09-05 11:40:42,101 - src.core.enhanced_tuner - INFO - æœ€çµ‚ç¢ºèªæˆåŠŸ: num_gpu = 101
2025-09-05 11:40:42,104 - src.core.enhanced_tuner - INFO - å¢å¼·èª¿æ ¡å®Œæˆ
2025-09-05 11:40:43,586 - src.utils.memory_monitor - INFO - è¨˜æ†¶é«”ç›£æ§å·²åœæ­¢
2025-09-05 11:40:57,951 - werkzeug - INFO - 127.0.0.1 - - [05/Sep/2025 11:40:57] "GET /enhanced_ollama_tuner_report.html HTTP/1.1" 200 -
2025-09-05 11:52:48,921 - __main__ - INFO - æ¥æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œæ­£åœ¨é—œé–‰...
2025-09-05 11:52:48,921 - src.utils.memory_monitor - INFO - è¨˜æ†¶é«”ç›£æ§å·²åœæ­¢
2025-09-05 11:52:48,921 - __main__ - INFO - ç¨‹å¼åŸ·è¡Œå®Œæˆ
